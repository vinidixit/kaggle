{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "187c47ed-f68b-7abe-05d8-1296a816ecca"
   },
   "source": [
    "This kernel presents an extensible approach to handling the Quora Question Pairs competition with a deep neural network. Using the final model's predictions should yield ~0.35 on the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7838992e-246a-8dd9-d7cf-ee5f3f04ab6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import gensim\n",
    "import pickle\n",
    "import logging\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "efc61246-e00c-32b6-f021-fdc6d78b02b6"
   },
   "source": [
    "### Define some useful functions we need to represent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5518a5ba-5790-d088-d41e-8df28e533c3a"
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    " \n",
    "def preprocess(text, min_length=2, swords=set()):\n",
    "    \"\"\"\n",
    "    Does preprocessing on an input string by lowering it, tokenizing, filtering out stopwords,\n",
    "    tokens shorter than min_length and tokens consisting of not English letters.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    words = map(lambda word: word.lower(), nltk.word_tokenize(text))\n",
    "    words = [word for word in words if word not in swords]\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length, words))\n",
    "    return filtered_tokens\n",
    "\n",
    "def build_vocab(tokenlists, max_size=20000, emb_model=None):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary of at most max_size words from the supplied list of lists of tokens.\n",
    "    If a word embedding model is provided, adds only the words present in the model vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    all_words = list(itertools.chain.from_iterable(tokenlists))\n",
    "    counter = Counter(all_words)\n",
    "    if emb_model:\n",
    "        counter = Counter(x for x in counter if x in emb_model)\n",
    "            \n",
    "    vocab = counter.most_common(max_size-2)\n",
    "\n",
    "    voc_words = [k[0] for k in vocab]\n",
    "\n",
    "    voc = {}\n",
    "    voc['NULL'] = 0\n",
    "    voc['UNKN'] = 1\n",
    "    for i, k in enumerate(voc_words):\n",
    "        voc[k] = i+2\n",
    "\n",
    "    rvoc = {v: k for k, v in voc.items()}\n",
    "\n",
    "    return voc, rvoc\n",
    "\n",
    "def vectorize_tokens(tokens, token_to_id, max_len):\n",
    "    \"\"\"\n",
    "    Converts a list of tokens to a list of token ids using the supplied dictionary.\n",
    "    Pads resulting list with NULL identifiers up to max_len length.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    for token in tokens:\n",
    "        ids.append(token_to_id.get(token, voc[\"UNKN\"]))\n",
    "\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += (max_len-len(ids))*[token_to_id[\"NULL\"]]\n",
    "\n",
    "    return ids\n",
    "\n",
    "def vectorize(tok_lists, token_to_id, max_len=150):\n",
    "    \"\"\"\n",
    "    Converts a list of lists of tokens to a numpy array of token identifiers\n",
    "    \"\"\"\n",
    "    \n",
    "    token_matrix = []\n",
    "        \n",
    "    for tok_list in tok_lists:\n",
    "        token_ids = vectorize_tokens(tok_list, token_to_id, max_len)\n",
    "        token_matrix.append(token_ids)\n",
    "    \n",
    "    token_matrix = np.array(token_matrix)\n",
    "        \n",
    "    return token_matrix\n",
    "\n",
    "def get_embeddings(model, rev_voc, dim=300):\n",
    "\n",
    "    myembeddings = []\n",
    "    for key in sorted(rev_voc.keys()):\n",
    "        val = rev_voc[key]\n",
    "        if val == 'NULL':\n",
    "            myembeddings.append(np.zeros((dim,)))\n",
    "        elif val == 'UNKN':\n",
    "            myembeddings.append(np.random.normal(size=(dim,)))\n",
    "        else:\n",
    "            try:\n",
    "                myembeddings.append(model[val])\n",
    "            except KeyError:\n",
    "                print(\"OOV: {}\".format(val))\n",
    "                myembeddings.append(np.random.normal(size=(dim,)))\n",
    "\n",
    "    myembeddings = np.array(myembeddings)\n",
    "    return myembeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2144d5a2-4e52-eb98-7f12-af72b392f07f"
   },
   "source": [
    "### Load train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "fcfc81ee-f223-b263-0acc-bfafe5c722fb"
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"/kaggle/input/train.csv\")\n",
    "testing_data = pd.read_csv(\"/kaggle/input/test.csv\")\n",
    "labels = np.array(list(training_data['is_duplicate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec573f73-bf0a-d008-7d32-c11b5fcd4105"
   },
   "source": [
    "### Preprocess all texts from train/test. \n",
    "This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "985635ab-df43-e145-d3eb-b81a9d10f955"
   },
   "outputs": [],
   "source": [
    "tr_q1_preprocessed = [preprocess(t, swords=stopwords) for t in training_data['question1']]\n",
    "tr_q2_preprocessed = [preprocess(t, swords=stopwords) for t in training_data['question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "25acd727-a70d-98a6-1734-0275916e2894"
   },
   "outputs": [],
   "source": [
    "ts_q1_preprocessed = [preprocess(t, swords=stopwords) for t in testing_data['question1']]\n",
    "ts_q2_preprocessed = [preprocess(t, swords=stopwords) for t in testing_data['question2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c718bdb6-e4a5-4251-ef61-48f8237cb4c2"
   },
   "source": [
    "### Load the word embedding model\n",
    "You can get it at https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit (1.5 GB download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "4251ec8e-6811-11e1-591c-f00bb82a07ab"
   },
   "outputs": [
    {
     "ename": "DeprecationWarning",
     "evalue": "Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fc0fcb97b0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m emb_mod = gensim.models.Word2Vec.load_word2vec_format(\"./assets/GoogleNews-vectors-negative300.bin\", \n\u001b[0;32m----> 2\u001b[0;31m                                                       binary=True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1298\u001b[0m             limit=None, datatype=REAL):\n\u001b[1;32m   1299\u001b[0m         \u001b[0;34m\"\"\"Deprecated. Use :meth:`gensim.models.KeyedVectors.load_word2vec_format` instead.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: Deprecated. Use gensim.models.KeyedVectors.load_word2vec_format instead."
     ]
    }
   ],
   "source": [
    "emb_mod = gensim.models.Word2Vec.load_word2vec_format(\"./assets/GoogleNews-vectors-negative300.bin\", \n",
    "                                                      binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5f49567-2371-31c9-ce8b-b243f6106544"
   },
   "source": [
    "###(Alternative) Learn the word embedding model\n",
    "Instead of using an external word-embedding model, we might just learn our own from the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "9c5458ee-ac88-656c-5823-fd0cecc8cccb"
   },
   "outputs": [],
   "source": [
    "all_texts = tr_q1_preprocessed+tr_q2_preprocessed+ts_q1_preprocessed+ts_q2_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "0715840a-d9a4-e7dd-3a0c-ce147924af1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 19:56:47,587 : INFO : collecting all words and their counts\n",
      "2019-05-04 19:56:47,589 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-04 19:56:47,607 : INFO : PROGRESS: at sentence #10000, processed 53138 words, keeping 11633 word types\n",
      "2019-05-04 19:56:47,625 : INFO : PROGRESS: at sentence #20000, processed 106530 words, keeping 16926 word types\n",
      "2019-05-04 19:56:47,642 : INFO : PROGRESS: at sentence #30000, processed 159667 words, keeping 20930 word types\n",
      "2019-05-04 19:56:47,660 : INFO : PROGRESS: at sentence #40000, processed 212333 words, keeping 24180 word types\n",
      "2019-05-04 19:56:47,678 : INFO : PROGRESS: at sentence #50000, processed 265683 words, keeping 27183 word types\n",
      "2019-05-04 19:56:47,696 : INFO : PROGRESS: at sentence #60000, processed 318740 words, keeping 29815 word types\n",
      "2019-05-04 19:56:47,715 : INFO : PROGRESS: at sentence #70000, processed 371726 words, keeping 32168 word types\n",
      "2019-05-04 19:56:47,733 : INFO : PROGRESS: at sentence #80000, processed 424975 words, keeping 34219 word types\n",
      "2019-05-04 19:56:47,752 : INFO : PROGRESS: at sentence #90000, processed 478111 words, keeping 36239 word types\n",
      "2019-05-04 19:56:47,771 : INFO : PROGRESS: at sentence #100000, processed 531208 words, keeping 38185 word types\n",
      "2019-05-04 19:56:47,791 : INFO : PROGRESS: at sentence #110000, processed 583676 words, keeping 39980 word types\n",
      "2019-05-04 19:56:47,810 : INFO : PROGRESS: at sentence #120000, processed 636636 words, keeping 41684 word types\n",
      "2019-05-04 19:56:47,831 : INFO : PROGRESS: at sentence #130000, processed 689919 words, keeping 43428 word types\n",
      "2019-05-04 19:56:47,851 : INFO : PROGRESS: at sentence #140000, processed 743035 words, keeping 44988 word types\n",
      "2019-05-04 19:56:47,874 : INFO : PROGRESS: at sentence #150000, processed 796557 words, keeping 46596 word types\n",
      "2019-05-04 19:56:47,894 : INFO : PROGRESS: at sentence #160000, processed 849960 words, keeping 48143 word types\n",
      "2019-05-04 19:56:47,915 : INFO : PROGRESS: at sentence #170000, processed 903330 words, keeping 49611 word types\n",
      "2019-05-04 19:56:47,935 : INFO : PROGRESS: at sentence #180000, processed 956748 words, keeping 51059 word types\n",
      "2019-05-04 19:56:47,955 : INFO : PROGRESS: at sentence #190000, processed 1009964 words, keeping 52405 word types\n",
      "2019-05-04 19:56:47,975 : INFO : PROGRESS: at sentence #200000, processed 1062725 words, keeping 53753 word types\n",
      "2019-05-04 19:56:47,994 : INFO : PROGRESS: at sentence #210000, processed 1115524 words, keeping 55025 word types\n",
      "2019-05-04 19:56:48,013 : INFO : PROGRESS: at sentence #220000, processed 1168501 words, keeping 56212 word types\n",
      "2019-05-04 19:56:48,033 : INFO : PROGRESS: at sentence #230000, processed 1222139 words, keeping 57448 word types\n",
      "2019-05-04 19:56:48,054 : INFO : PROGRESS: at sentence #240000, processed 1275224 words, keeping 58610 word types\n",
      "2019-05-04 19:56:48,073 : INFO : PROGRESS: at sentence #250000, processed 1328924 words, keeping 59783 word types\n",
      "2019-05-04 19:56:48,092 : INFO : PROGRESS: at sentence #260000, processed 1382578 words, keeping 60994 word types\n",
      "2019-05-04 19:56:48,113 : INFO : PROGRESS: at sentence #270000, processed 1436299 words, keeping 62109 word types\n",
      "2019-05-04 19:56:48,134 : INFO : PROGRESS: at sentence #280000, processed 1489351 words, keeping 63190 word types\n",
      "2019-05-04 19:56:48,154 : INFO : PROGRESS: at sentence #290000, processed 1542684 words, keeping 64285 word types\n",
      "2019-05-04 19:56:48,174 : INFO : PROGRESS: at sentence #300000, processed 1595555 words, keeping 65367 word types\n",
      "2019-05-04 19:56:48,193 : INFO : PROGRESS: at sentence #310000, processed 1648775 words, keeping 66402 word types\n",
      "2019-05-04 19:56:48,212 : INFO : PROGRESS: at sentence #320000, processed 1701809 words, keeping 67412 word types\n",
      "2019-05-04 19:56:48,232 : INFO : PROGRESS: at sentence #330000, processed 1755336 words, keeping 68453 word types\n",
      "2019-05-04 19:56:48,251 : INFO : PROGRESS: at sentence #340000, processed 1808389 words, keeping 69393 word types\n",
      "2019-05-04 19:56:48,271 : INFO : PROGRESS: at sentence #350000, processed 1861674 words, keeping 70308 word types\n",
      "2019-05-04 19:56:48,290 : INFO : PROGRESS: at sentence #360000, processed 1914806 words, keeping 71222 word types\n",
      "2019-05-04 19:56:48,310 : INFO : PROGRESS: at sentence #370000, processed 1968139 words, keeping 72145 word types\n",
      "2019-05-04 19:56:48,330 : INFO : PROGRESS: at sentence #380000, processed 2021680 words, keeping 73085 word types\n",
      "2019-05-04 19:56:48,350 : INFO : PROGRESS: at sentence #390000, processed 2075776 words, keeping 74058 word types\n",
      "2019-05-04 19:56:48,371 : INFO : PROGRESS: at sentence #400000, processed 2129417 words, keeping 74932 word types\n",
      "2019-05-04 19:56:48,391 : INFO : PROGRESS: at sentence #410000, processed 2183127 words, keeping 75733 word types\n",
      "2019-05-04 19:56:48,410 : INFO : PROGRESS: at sentence #420000, processed 2236697 words, keeping 76451 word types\n",
      "2019-05-04 19:56:48,430 : INFO : PROGRESS: at sentence #430000, processed 2290652 words, keeping 77219 word types\n",
      "2019-05-04 19:56:48,449 : INFO : PROGRESS: at sentence #440000, processed 2344292 words, keeping 77905 word types\n",
      "2019-05-04 19:56:48,468 : INFO : PROGRESS: at sentence #450000, processed 2398396 words, keeping 78581 word types\n",
      "2019-05-04 19:56:48,488 : INFO : PROGRESS: at sentence #460000, processed 2452256 words, keeping 79260 word types\n",
      "2019-05-04 19:56:48,507 : INFO : PROGRESS: at sentence #470000, processed 2505928 words, keeping 79922 word types\n",
      "2019-05-04 19:56:48,526 : INFO : PROGRESS: at sentence #480000, processed 2559763 words, keeping 80629 word types\n",
      "2019-05-04 19:56:48,545 : INFO : PROGRESS: at sentence #490000, processed 2613806 words, keeping 81274 word types\n",
      "2019-05-04 19:56:48,564 : INFO : PROGRESS: at sentence #500000, processed 2667735 words, keeping 81952 word types\n",
      "2019-05-04 19:56:48,584 : INFO : PROGRESS: at sentence #510000, processed 2720620 words, keeping 82602 word types\n",
      "2019-05-04 19:56:48,604 : INFO : PROGRESS: at sentence #520000, processed 2774196 words, keeping 83220 word types\n",
      "2019-05-04 19:56:48,625 : INFO : PROGRESS: at sentence #530000, processed 2828353 words, keeping 83828 word types\n",
      "2019-05-04 19:56:48,645 : INFO : PROGRESS: at sentence #540000, processed 2882482 words, keeping 84512 word types\n",
      "2019-05-04 19:56:48,665 : INFO : PROGRESS: at sentence #550000, processed 2936778 words, keeping 85171 word types\n",
      "2019-05-04 19:56:48,684 : INFO : PROGRESS: at sentence #560000, processed 2990746 words, keeping 85809 word types\n",
      "2019-05-04 19:56:48,704 : INFO : PROGRESS: at sentence #570000, processed 3044948 words, keeping 86420 word types\n",
      "2019-05-04 19:56:48,724 : INFO : PROGRESS: at sentence #580000, processed 3099187 words, keeping 87025 word types\n",
      "2019-05-04 19:56:48,747 : INFO : PROGRESS: at sentence #590000, processed 3153531 words, keeping 87615 word types\n",
      "2019-05-04 19:56:48,766 : INFO : PROGRESS: at sentence #600000, processed 3206718 words, keeping 88149 word types\n",
      "2019-05-04 19:56:48,786 : INFO : PROGRESS: at sentence #610000, processed 3260703 words, keeping 88769 word types\n",
      "2019-05-04 19:56:48,807 : INFO : PROGRESS: at sentence #620000, processed 3314479 words, keeping 89367 word types\n",
      "2019-05-04 19:56:48,828 : INFO : PROGRESS: at sentence #630000, processed 3368223 words, keeping 90020 word types\n",
      "2019-05-04 19:56:48,847 : INFO : PROGRESS: at sentence #640000, processed 3421388 words, keeping 90583 word types\n",
      "2019-05-04 19:56:48,867 : INFO : PROGRESS: at sentence #650000, processed 3475463 words, keeping 91188 word types\n",
      "2019-05-04 19:56:48,888 : INFO : PROGRESS: at sentence #660000, processed 3529190 words, keeping 91811 word types\n",
      "2019-05-04 19:56:48,909 : INFO : PROGRESS: at sentence #670000, processed 3583320 words, keeping 92395 word types\n",
      "2019-05-04 19:56:48,930 : INFO : PROGRESS: at sentence #680000, processed 3637574 words, keeping 92997 word types\n",
      "2019-05-04 19:56:48,950 : INFO : PROGRESS: at sentence #690000, processed 3691400 words, keeping 93580 word types\n",
      "2019-05-04 19:56:48,971 : INFO : PROGRESS: at sentence #700000, processed 3745158 words, keeping 94177 word types\n",
      "2019-05-04 19:56:48,990 : INFO : PROGRESS: at sentence #710000, processed 3798559 words, keeping 94735 word types\n",
      "2019-05-04 19:56:49,010 : INFO : PROGRESS: at sentence #720000, processed 3852532 words, keeping 95295 word types\n",
      "2019-05-04 19:56:49,030 : INFO : PROGRESS: at sentence #730000, processed 3905914 words, keeping 95818 word types\n",
      "2019-05-04 19:56:49,052 : INFO : PROGRESS: at sentence #740000, processed 3959715 words, keeping 96363 word types\n",
      "2019-05-04 19:56:49,073 : INFO : PROGRESS: at sentence #750000, processed 4013261 words, keeping 96905 word types\n",
      "2019-05-04 19:56:49,094 : INFO : PROGRESS: at sentence #760000, processed 4067286 words, keeping 97452 word types\n",
      "2019-05-04 19:56:49,114 : INFO : PROGRESS: at sentence #770000, processed 4121202 words, keeping 98013 word types\n",
      "2019-05-04 19:56:49,134 : INFO : PROGRESS: at sentence #780000, processed 4175172 words, keeping 98558 word types\n",
      "2019-05-04 19:56:49,155 : INFO : PROGRESS: at sentence #790000, processed 4229171 words, keeping 99129 word types\n",
      "2019-05-04 19:56:49,176 : INFO : PROGRESS: at sentence #800000, processed 4283841 words, keeping 99660 word types\n",
      "2019-05-04 19:56:49,196 : INFO : PROGRESS: at sentence #810000, processed 4338322 words, keeping 100260 word types\n",
      "2019-05-04 19:56:49,217 : INFO : PROGRESS: at sentence #820000, processed 4392535 words, keeping 101083 word types\n",
      "2019-05-04 19:56:49,238 : INFO : PROGRESS: at sentence #830000, processed 4447371 words, keeping 101849 word types\n",
      "2019-05-04 19:56:49,259 : INFO : PROGRESS: at sentence #840000, processed 4502350 words, keeping 102630 word types\n",
      "2019-05-04 19:56:49,281 : INFO : PROGRESS: at sentence #850000, processed 4557201 words, keeping 103363 word types\n",
      "2019-05-04 19:56:49,301 : INFO : PROGRESS: at sentence #860000, processed 4611848 words, keeping 104120 word types\n",
      "2019-05-04 19:56:49,323 : INFO : PROGRESS: at sentence #870000, processed 4666843 words, keeping 104899 word types\n",
      "2019-05-04 19:56:49,344 : INFO : PROGRESS: at sentence #880000, processed 4721582 words, keeping 105679 word types\n",
      "2019-05-04 19:56:49,366 : INFO : PROGRESS: at sentence #890000, processed 4776486 words, keeping 106389 word types\n",
      "2019-05-04 19:56:49,388 : INFO : PROGRESS: at sentence #900000, processed 4831527 words, keeping 107070 word types\n",
      "2019-05-04 19:56:49,410 : INFO : PROGRESS: at sentence #910000, processed 4886742 words, keeping 107767 word types\n",
      "2019-05-04 19:56:49,432 : INFO : PROGRESS: at sentence #920000, processed 4941240 words, keeping 108449 word types\n",
      "2019-05-04 19:56:49,454 : INFO : PROGRESS: at sentence #930000, processed 4996118 words, keeping 109068 word types\n",
      "2019-05-04 19:56:49,475 : INFO : PROGRESS: at sentence #940000, processed 5051447 words, keeping 109688 word types\n",
      "2019-05-04 19:56:49,496 : INFO : PROGRESS: at sentence #950000, processed 5106064 words, keeping 110319 word types\n",
      "2019-05-04 19:56:49,517 : INFO : PROGRESS: at sentence #960000, processed 5161045 words, keeping 110961 word types\n",
      "2019-05-04 19:56:49,537 : INFO : PROGRESS: at sentence #970000, processed 5215898 words, keeping 111517 word types\n",
      "2019-05-04 19:56:49,559 : INFO : PROGRESS: at sentence #980000, processed 5271353 words, keeping 112068 word types\n",
      "2019-05-04 19:56:49,580 : INFO : PROGRESS: at sentence #990000, processed 5326745 words, keeping 112692 word types\n",
      "2019-05-04 19:56:49,601 : INFO : PROGRESS: at sentence #1000000, processed 5381944 words, keeping 113262 word types\n",
      "2019-05-04 19:56:49,622 : INFO : PROGRESS: at sentence #1010000, processed 5436786 words, keeping 113804 word types\n",
      "2019-05-04 19:56:49,643 : INFO : PROGRESS: at sentence #1020000, processed 5491441 words, keeping 114307 word types\n",
      "2019-05-04 19:56:49,664 : INFO : PROGRESS: at sentence #1030000, processed 5546421 words, keeping 114850 word types\n",
      "2019-05-04 19:56:49,685 : INFO : PROGRESS: at sentence #1040000, processed 5600781 words, keeping 115390 word types\n",
      "2019-05-04 19:56:49,706 : INFO : PROGRESS: at sentence #1050000, processed 5655494 words, keeping 115902 word types\n",
      "2019-05-04 19:56:49,728 : INFO : PROGRESS: at sentence #1060000, processed 5709570 words, keeping 116406 word types\n",
      "2019-05-04 19:56:49,749 : INFO : PROGRESS: at sentence #1070000, processed 5764308 words, keeping 116865 word types\n",
      "2019-05-04 19:56:49,769 : INFO : PROGRESS: at sentence #1080000, processed 5818275 words, keeping 117325 word types\n",
      "2019-05-04 19:56:49,791 : INFO : PROGRESS: at sentence #1090000, processed 5873230 words, keeping 117819 word types\n",
      "2019-05-04 19:56:49,812 : INFO : PROGRESS: at sentence #1100000, processed 5928614 words, keeping 118307 word types\n",
      "2019-05-04 19:56:49,833 : INFO : PROGRESS: at sentence #1110000, processed 5983658 words, keeping 118727 word types\n",
      "2019-05-04 19:56:49,853 : INFO : PROGRESS: at sentence #1120000, processed 6038658 words, keeping 119150 word types\n",
      "2019-05-04 19:56:49,874 : INFO : PROGRESS: at sentence #1130000, processed 6093746 words, keeping 119602 word types\n",
      "2019-05-04 19:56:49,896 : INFO : PROGRESS: at sentence #1140000, processed 6148346 words, keeping 120044 word types\n",
      "2019-05-04 19:56:49,917 : INFO : PROGRESS: at sentence #1150000, processed 6203322 words, keeping 120490 word types\n",
      "2019-05-04 19:56:49,938 : INFO : PROGRESS: at sentence #1160000, processed 6258625 words, keeping 120919 word types\n",
      "2019-05-04 19:56:49,959 : INFO : PROGRESS: at sentence #1170000, processed 6313416 words, keeping 121319 word types\n",
      "2019-05-04 19:56:49,980 : INFO : PROGRESS: at sentence #1180000, processed 6368431 words, keeping 121723 word types\n",
      "2019-05-04 19:56:50,000 : INFO : PROGRESS: at sentence #1190000, processed 6423219 words, keeping 122114 word types\n",
      "2019-05-04 19:56:50,021 : INFO : PROGRESS: at sentence #1200000, processed 6477741 words, keeping 122508 word types\n",
      "2019-05-04 19:56:50,041 : INFO : PROGRESS: at sentence #1210000, processed 6532693 words, keeping 122889 word types\n",
      "2019-05-04 19:56:50,063 : INFO : PROGRESS: at sentence #1220000, processed 6586863 words, keeping 123291 word types\n",
      "2019-05-04 19:56:50,083 : INFO : PROGRESS: at sentence #1230000, processed 6640812 words, keeping 123648 word types\n",
      "2019-05-04 19:56:50,104 : INFO : PROGRESS: at sentence #1240000, processed 6694981 words, keeping 123982 word types\n",
      "2019-05-04 19:56:50,125 : INFO : PROGRESS: at sentence #1250000, processed 6749851 words, keeping 124323 word types\n",
      "2019-05-04 19:56:50,146 : INFO : PROGRESS: at sentence #1260000, processed 6804648 words, keeping 124698 word types\n",
      "2019-05-04 19:56:50,166 : INFO : PROGRESS: at sentence #1270000, processed 6859090 words, keeping 125107 word types\n",
      "2019-05-04 19:56:50,186 : INFO : PROGRESS: at sentence #1280000, processed 6914371 words, keeping 125441 word types\n",
      "2019-05-04 19:56:50,206 : INFO : PROGRESS: at sentence #1290000, processed 6969431 words, keeping 125765 word types\n",
      "2019-05-04 19:56:50,227 : INFO : PROGRESS: at sentence #1300000, processed 7024593 words, keeping 126095 word types\n",
      "2019-05-04 19:56:50,247 : INFO : PROGRESS: at sentence #1310000, processed 7079505 words, keeping 126450 word types\n",
      "2019-05-04 19:56:50,268 : INFO : PROGRESS: at sentence #1320000, processed 7134250 words, keeping 126805 word types\n",
      "2019-05-04 19:56:50,288 : INFO : PROGRESS: at sentence #1330000, processed 7188908 words, keeping 127130 word types\n",
      "2019-05-04 19:56:50,308 : INFO : PROGRESS: at sentence #1340000, processed 7243561 words, keeping 127437 word types\n",
      "2019-05-04 19:56:50,328 : INFO : PROGRESS: at sentence #1350000, processed 7298232 words, keeping 127722 word types\n",
      "2019-05-04 19:56:50,348 : INFO : PROGRESS: at sentence #1360000, processed 7353545 words, keeping 128043 word types\n",
      "2019-05-04 19:56:50,368 : INFO : PROGRESS: at sentence #1370000, processed 7408394 words, keeping 128343 word types\n",
      "2019-05-04 19:56:50,389 : INFO : PROGRESS: at sentence #1380000, processed 7463182 words, keeping 128646 word types\n",
      "2019-05-04 19:56:50,409 : INFO : PROGRESS: at sentence #1390000, processed 7517918 words, keeping 128976 word types\n",
      "2019-05-04 19:56:50,430 : INFO : PROGRESS: at sentence #1400000, processed 7572848 words, keeping 129264 word types\n",
      "2019-05-04 19:56:50,451 : INFO : PROGRESS: at sentence #1410000, processed 7627460 words, keeping 129583 word types\n",
      "2019-05-04 19:56:50,471 : INFO : PROGRESS: at sentence #1420000, processed 7682468 words, keeping 129860 word types\n",
      "2019-05-04 19:56:50,491 : INFO : PROGRESS: at sentence #1430000, processed 7737124 words, keeping 130156 word types\n",
      "2019-05-04 19:56:50,511 : INFO : PROGRESS: at sentence #1440000, processed 7791690 words, keeping 130418 word types\n",
      "2019-05-04 19:56:50,532 : INFO : PROGRESS: at sentence #1450000, processed 7846599 words, keeping 130696 word types\n",
      "2019-05-04 19:56:50,552 : INFO : PROGRESS: at sentence #1460000, processed 7901857 words, keeping 130947 word types\n",
      "2019-05-04 19:56:50,572 : INFO : PROGRESS: at sentence #1470000, processed 7956529 words, keeping 131238 word types\n",
      "2019-05-04 19:56:50,593 : INFO : PROGRESS: at sentence #1480000, processed 8011404 words, keeping 131509 word types\n",
      "2019-05-04 19:56:50,614 : INFO : PROGRESS: at sentence #1490000, processed 8066215 words, keeping 131758 word types\n",
      "2019-05-04 19:56:50,634 : INFO : PROGRESS: at sentence #1500000, processed 8121409 words, keeping 132010 word types\n",
      "2019-05-04 19:56:50,655 : INFO : PROGRESS: at sentence #1510000, processed 8176523 words, keeping 132231 word types\n",
      "2019-05-04 19:56:50,675 : INFO : PROGRESS: at sentence #1520000, processed 8230909 words, keeping 132459 word types\n",
      "2019-05-04 19:56:50,696 : INFO : PROGRESS: at sentence #1530000, processed 8286180 words, keeping 132719 word types\n",
      "2019-05-04 19:56:50,716 : INFO : PROGRESS: at sentence #1540000, processed 8340111 words, keeping 132968 word types\n",
      "2019-05-04 19:56:50,738 : INFO : PROGRESS: at sentence #1550000, processed 8395618 words, keeping 133232 word types\n",
      "2019-05-04 19:56:50,759 : INFO : PROGRESS: at sentence #1560000, processed 8450674 words, keeping 133470 word types\n",
      "2019-05-04 19:56:50,780 : INFO : PROGRESS: at sentence #1570000, processed 8505412 words, keeping 133682 word types\n",
      "2019-05-04 19:56:50,801 : INFO : PROGRESS: at sentence #1580000, processed 8560441 words, keeping 133891 word types\n",
      "2019-05-04 19:56:50,822 : INFO : PROGRESS: at sentence #1590000, processed 8615111 words, keeping 134132 word types\n",
      "2019-05-04 19:56:50,842 : INFO : PROGRESS: at sentence #1600000, processed 8669998 words, keeping 134356 word types\n",
      "2019-05-04 19:56:50,863 : INFO : PROGRESS: at sentence #1610000, processed 8724182 words, keeping 134566 word types\n",
      "2019-05-04 19:56:50,885 : INFO : PROGRESS: at sentence #1620000, processed 8779199 words, keeping 134775 word types\n",
      "2019-05-04 19:56:50,907 : INFO : PROGRESS: at sentence #1630000, processed 8834381 words, keeping 134984 word types\n",
      "2019-05-04 19:56:50,929 : INFO : PROGRESS: at sentence #1640000, processed 8889027 words, keeping 135182 word types\n",
      "2019-05-04 19:56:50,949 : INFO : PROGRESS: at sentence #1650000, processed 8944149 words, keeping 135383 word types\n",
      "2019-05-04 19:56:50,970 : INFO : PROGRESS: at sentence #1660000, processed 8998971 words, keeping 135579 word types\n",
      "2019-05-04 19:56:50,990 : INFO : PROGRESS: at sentence #1670000, processed 9053523 words, keeping 135769 word types\n",
      "2019-05-04 19:56:51,010 : INFO : PROGRESS: at sentence #1680000, processed 9107962 words, keeping 135976 word types\n",
      "2019-05-04 19:56:51,031 : INFO : PROGRESS: at sentence #1690000, processed 9162535 words, keeping 136150 word types\n",
      "2019-05-04 19:56:51,053 : INFO : PROGRESS: at sentence #1700000, processed 9216958 words, keeping 136349 word types\n",
      "2019-05-04 19:56:51,073 : INFO : PROGRESS: at sentence #1710000, processed 9271460 words, keeping 136523 word types\n",
      "2019-05-04 19:56:51,094 : INFO : PROGRESS: at sentence #1720000, processed 9327048 words, keeping 136673 word types\n",
      "2019-05-04 19:56:51,114 : INFO : PROGRESS: at sentence #1730000, processed 9381800 words, keeping 136855 word types\n",
      "2019-05-04 19:56:51,134 : INFO : PROGRESS: at sentence #1740000, processed 9436363 words, keeping 137025 word types\n",
      "2019-05-04 19:56:51,155 : INFO : PROGRESS: at sentence #1750000, processed 9491301 words, keeping 137211 word types\n",
      "2019-05-04 19:56:51,176 : INFO : PROGRESS: at sentence #1760000, processed 9545966 words, keeping 137360 word types\n",
      "2019-05-04 19:56:51,196 : INFO : PROGRESS: at sentence #1770000, processed 9600908 words, keeping 137519 word types\n",
      "2019-05-04 19:56:51,216 : INFO : PROGRESS: at sentence #1780000, processed 9655425 words, keeping 137668 word types\n",
      "2019-05-04 19:56:51,237 : INFO : PROGRESS: at sentence #1790000, processed 9710009 words, keeping 137853 word types\n",
      "2019-05-04 19:56:51,258 : INFO : PROGRESS: at sentence #1800000, processed 9764591 words, keeping 138011 word types\n",
      "2019-05-04 19:56:51,278 : INFO : PROGRESS: at sentence #1810000, processed 9819435 words, keeping 138177 word types\n",
      "2019-05-04 19:56:51,299 : INFO : PROGRESS: at sentence #1820000, processed 9874245 words, keeping 138314 word types\n",
      "2019-05-04 19:56:51,319 : INFO : PROGRESS: at sentence #1830000, processed 9929376 words, keeping 138453 word types\n",
      "2019-05-04 19:56:51,340 : INFO : PROGRESS: at sentence #1840000, processed 9984573 words, keeping 138597 word types\n",
      "2019-05-04 19:56:51,360 : INFO : PROGRESS: at sentence #1850000, processed 10039341 words, keeping 138737 word types\n",
      "2019-05-04 19:56:51,380 : INFO : PROGRESS: at sentence #1860000, processed 10093986 words, keeping 138896 word types\n",
      "2019-05-04 19:56:51,401 : INFO : PROGRESS: at sentence #1870000, processed 10148755 words, keeping 139035 word types\n",
      "2019-05-04 19:56:51,421 : INFO : PROGRESS: at sentence #1880000, processed 10203606 words, keeping 139166 word types\n",
      "2019-05-04 19:56:51,441 : INFO : PROGRESS: at sentence #1890000, processed 10258024 words, keeping 139276 word types\n",
      "2019-05-04 19:56:51,462 : INFO : PROGRESS: at sentence #1900000, processed 10312884 words, keeping 139410 word types\n",
      "2019-05-04 19:56:51,483 : INFO : PROGRESS: at sentence #1910000, processed 10367527 words, keeping 139553 word types\n",
      "2019-05-04 19:56:51,504 : INFO : PROGRESS: at sentence #1920000, processed 10422635 words, keeping 139719 word types\n",
      "2019-05-04 19:56:51,524 : INFO : PROGRESS: at sentence #1930000, processed 10477521 words, keeping 139831 word types\n",
      "2019-05-04 19:56:51,544 : INFO : PROGRESS: at sentence #1940000, processed 10531624 words, keeping 139950 word types\n",
      "2019-05-04 19:56:51,565 : INFO : PROGRESS: at sentence #1950000, processed 10586210 words, keeping 140053 word types\n",
      "2019-05-04 19:56:51,585 : INFO : PROGRESS: at sentence #1960000, processed 10640802 words, keeping 140178 word types\n",
      "2019-05-04 19:56:51,606 : INFO : PROGRESS: at sentence #1970000, processed 10696185 words, keeping 140309 word types\n",
      "2019-05-04 19:56:51,628 : INFO : PROGRESS: at sentence #1980000, processed 10750797 words, keeping 140426 word types\n",
      "2019-05-04 19:56:51,648 : INFO : PROGRESS: at sentence #1990000, processed 10805378 words, keeping 140533 word types\n",
      "2019-05-04 19:56:51,669 : INFO : PROGRESS: at sentence #2000000, processed 10860276 words, keeping 140664 word types\n",
      "2019-05-04 19:56:51,689 : INFO : PROGRESS: at sentence #2010000, processed 10914776 words, keeping 140797 word types\n",
      "2019-05-04 19:56:51,709 : INFO : PROGRESS: at sentence #2020000, processed 10969890 words, keeping 140898 word types\n",
      "2019-05-04 19:56:51,730 : INFO : PROGRESS: at sentence #2030000, processed 11024397 words, keeping 140975 word types\n",
      "2019-05-04 19:56:51,750 : INFO : PROGRESS: at sentence #2040000, processed 11078982 words, keeping 141102 word types\n",
      "2019-05-04 19:56:51,770 : INFO : PROGRESS: at sentence #2050000, processed 11133265 words, keeping 141205 word types\n",
      "2019-05-04 19:56:51,791 : INFO : PROGRESS: at sentence #2060000, processed 11188458 words, keeping 141312 word types\n",
      "2019-05-04 19:56:51,811 : INFO : PROGRESS: at sentence #2070000, processed 11243267 words, keeping 141411 word types\n",
      "2019-05-04 19:56:51,832 : INFO : PROGRESS: at sentence #2080000, processed 11297980 words, keeping 141496 word types\n",
      "2019-05-04 19:56:51,854 : INFO : PROGRESS: at sentence #2090000, processed 11352493 words, keeping 141586 word types\n",
      "2019-05-04 19:56:51,875 : INFO : PROGRESS: at sentence #2100000, processed 11407313 words, keeping 141699 word types\n",
      "2019-05-04 19:56:51,897 : INFO : PROGRESS: at sentence #2110000, processed 11462087 words, keeping 141810 word types\n",
      "2019-05-04 19:56:51,918 : INFO : PROGRESS: at sentence #2120000, processed 11517013 words, keeping 141893 word types\n",
      "2019-05-04 19:56:51,940 : INFO : PROGRESS: at sentence #2130000, processed 11571755 words, keeping 141989 word types\n",
      "2019-05-04 19:56:51,962 : INFO : PROGRESS: at sentence #2140000, processed 11626540 words, keeping 142091 word types\n",
      "2019-05-04 19:56:51,983 : INFO : PROGRESS: at sentence #2150000, processed 11681393 words, keeping 142175 word types\n",
      "2019-05-04 19:56:52,004 : INFO : PROGRESS: at sentence #2160000, processed 11736234 words, keeping 142278 word types\n",
      "2019-05-04 19:56:52,025 : INFO : PROGRESS: at sentence #2170000, processed 11790698 words, keeping 142374 word types\n",
      "2019-05-04 19:56:52,047 : INFO : PROGRESS: at sentence #2180000, processed 11844881 words, keeping 142464 word types\n",
      "2019-05-04 19:56:52,068 : INFO : PROGRESS: at sentence #2190000, processed 11899902 words, keeping 142558 word types\n",
      "2019-05-04 19:56:52,089 : INFO : PROGRESS: at sentence #2200000, processed 11955159 words, keeping 142651 word types\n",
      "2019-05-04 19:56:52,110 : INFO : PROGRESS: at sentence #2210000, processed 12010251 words, keeping 142731 word types\n",
      "2019-05-04 19:56:52,130 : INFO : PROGRESS: at sentence #2220000, processed 12065105 words, keeping 142798 word types\n",
      "2019-05-04 19:56:52,150 : INFO : PROGRESS: at sentence #2230000, processed 12119596 words, keeping 142888 word types\n",
      "2019-05-04 19:56:52,170 : INFO : PROGRESS: at sentence #2240000, processed 12174882 words, keeping 142973 word types\n",
      "2019-05-04 19:56:52,191 : INFO : PROGRESS: at sentence #2250000, processed 12230000 words, keeping 143054 word types\n",
      "2019-05-04 19:56:52,212 : INFO : PROGRESS: at sentence #2260000, processed 12284929 words, keeping 143127 word types\n",
      "2019-05-04 19:56:52,233 : INFO : PROGRESS: at sentence #2270000, processed 12339949 words, keeping 143213 word types\n",
      "2019-05-04 19:56:52,253 : INFO : PROGRESS: at sentence #2280000, processed 12394576 words, keeping 143294 word types\n",
      "2019-05-04 19:56:52,273 : INFO : PROGRESS: at sentence #2290000, processed 12449433 words, keeping 143379 word types\n",
      "2019-05-04 19:56:52,294 : INFO : PROGRESS: at sentence #2300000, processed 12503954 words, keeping 143461 word types\n",
      "2019-05-04 19:56:52,315 : INFO : PROGRESS: at sentence #2310000, processed 12558209 words, keeping 143524 word types\n",
      "2019-05-04 19:56:52,336 : INFO : PROGRESS: at sentence #2320000, processed 12613816 words, keeping 143600 word types\n",
      "2019-05-04 19:56:52,356 : INFO : PROGRESS: at sentence #2330000, processed 12668656 words, keeping 143655 word types\n",
      "2019-05-04 19:56:52,377 : INFO : PROGRESS: at sentence #2340000, processed 12723693 words, keeping 143741 word types\n",
      "2019-05-04 19:56:52,398 : INFO : PROGRESS: at sentence #2350000, processed 12778455 words, keeping 143816 word types\n",
      "2019-05-04 19:56:52,418 : INFO : PROGRESS: at sentence #2360000, processed 12832885 words, keeping 143882 word types\n",
      "2019-05-04 19:56:52,439 : INFO : PROGRESS: at sentence #2370000, processed 12887450 words, keeping 143940 word types\n",
      "2019-05-04 19:56:52,458 : INFO : PROGRESS: at sentence #2380000, processed 12942324 words, keeping 144010 word types\n",
      "2019-05-04 19:56:52,479 : INFO : PROGRESS: at sentence #2390000, processed 12997450 words, keeping 144061 word types\n",
      "2019-05-04 19:56:52,499 : INFO : PROGRESS: at sentence #2400000, processed 13052060 words, keeping 144122 word types\n",
      "2019-05-04 19:56:52,520 : INFO : PROGRESS: at sentence #2410000, processed 13106253 words, keeping 144179 word types\n",
      "2019-05-04 19:56:52,540 : INFO : PROGRESS: at sentence #2420000, processed 13161418 words, keeping 144243 word types\n",
      "2019-05-04 19:56:52,561 : INFO : PROGRESS: at sentence #2430000, processed 13216267 words, keeping 144290 word types\n",
      "2019-05-04 19:56:52,582 : INFO : PROGRESS: at sentence #2440000, processed 13271156 words, keeping 144349 word types\n",
      "2019-05-04 19:56:52,603 : INFO : PROGRESS: at sentence #2450000, processed 13326430 words, keeping 144398 word types\n",
      "2019-05-04 19:56:52,623 : INFO : PROGRESS: at sentence #2460000, processed 13381332 words, keeping 144444 word types\n",
      "2019-05-04 19:56:52,646 : INFO : PROGRESS: at sentence #2470000, processed 13435923 words, keeping 144499 word types\n",
      "2019-05-04 19:56:52,667 : INFO : PROGRESS: at sentence #2480000, processed 13490800 words, keeping 144551 word types\n",
      "2019-05-04 19:56:52,688 : INFO : PROGRESS: at sentence #2490000, processed 13545975 words, keeping 144602 word types\n",
      "2019-05-04 19:56:52,709 : INFO : PROGRESS: at sentence #2500000, processed 13600841 words, keeping 144662 word types\n",
      "2019-05-04 19:56:52,730 : INFO : PROGRESS: at sentence #2510000, processed 13655868 words, keeping 144727 word types\n",
      "2019-05-04 19:56:52,750 : INFO : PROGRESS: at sentence #2520000, processed 13710537 words, keeping 144791 word types\n",
      "2019-05-04 19:56:52,771 : INFO : PROGRESS: at sentence #2530000, processed 13765565 words, keeping 144836 word types\n",
      "2019-05-04 19:56:52,792 : INFO : PROGRESS: at sentence #2540000, processed 13820084 words, keeping 144892 word types\n",
      "2019-05-04 19:56:52,814 : INFO : PROGRESS: at sentence #2550000, processed 13874709 words, keeping 144942 word types\n",
      "2019-05-04 19:56:52,835 : INFO : PROGRESS: at sentence #2560000, processed 13929488 words, keeping 144993 word types\n",
      "2019-05-04 19:56:52,855 : INFO : PROGRESS: at sentence #2570000, processed 13984533 words, keeping 145043 word types\n",
      "2019-05-04 19:56:52,875 : INFO : PROGRESS: at sentence #2580000, processed 14039150 words, keeping 145086 word types\n",
      "2019-05-04 19:56:52,896 : INFO : PROGRESS: at sentence #2590000, processed 14094187 words, keeping 145123 word types\n",
      "2019-05-04 19:56:52,919 : INFO : PROGRESS: at sentence #2600000, processed 14148935 words, keeping 145176 word types\n",
      "2019-05-04 19:56:52,940 : INFO : PROGRESS: at sentence #2610000, processed 14204028 words, keeping 145215 word types\n",
      "2019-05-04 19:56:52,962 : INFO : PROGRESS: at sentence #2620000, processed 14258847 words, keeping 145265 word types\n",
      "2019-05-04 19:56:52,984 : INFO : PROGRESS: at sentence #2630000, processed 14313937 words, keeping 145331 word types\n",
      "2019-05-04 19:56:53,006 : INFO : PROGRESS: at sentence #2640000, processed 14369127 words, keeping 145384 word types\n",
      "2019-05-04 19:56:53,028 : INFO : PROGRESS: at sentence #2650000, processed 14424002 words, keeping 145436 word types\n",
      "2019-05-04 19:56:53,051 : INFO : PROGRESS: at sentence #2660000, processed 14479584 words, keeping 145482 word types\n",
      "2019-05-04 19:56:53,075 : INFO : PROGRESS: at sentence #2670000, processed 14534622 words, keeping 145519 word types\n",
      "2019-05-04 19:56:53,096 : INFO : PROGRESS: at sentence #2680000, processed 14589285 words, keeping 145568 word types\n",
      "2019-05-04 19:56:53,118 : INFO : PROGRESS: at sentence #2690000, processed 14643766 words, keeping 145602 word types\n",
      "2019-05-04 19:56:53,140 : INFO : PROGRESS: at sentence #2700000, processed 14698119 words, keeping 145630 word types\n",
      "2019-05-04 19:56:53,160 : INFO : PROGRESS: at sentence #2710000, processed 14752606 words, keeping 145667 word types\n",
      "2019-05-04 19:56:53,181 : INFO : PROGRESS: at sentence #2720000, processed 14807922 words, keeping 145717 word types\n",
      "2019-05-04 19:56:53,202 : INFO : PROGRESS: at sentence #2730000, processed 14862435 words, keeping 145754 word types\n",
      "2019-05-04 19:56:53,224 : INFO : PROGRESS: at sentence #2740000, processed 14917237 words, keeping 145777 word types\n",
      "2019-05-04 19:56:53,246 : INFO : PROGRESS: at sentence #2750000, processed 14972438 words, keeping 145805 word types\n",
      "2019-05-04 19:56:53,268 : INFO : PROGRESS: at sentence #2760000, processed 15027148 words, keeping 145828 word types\n",
      "2019-05-04 19:56:53,290 : INFO : PROGRESS: at sentence #2770000, processed 15081801 words, keeping 145855 word types\n",
      "2019-05-04 19:56:53,316 : INFO : PROGRESS: at sentence #2780000, processed 15135998 words, keeping 145899 word types\n",
      "2019-05-04 19:56:53,340 : INFO : PROGRESS: at sentence #2790000, processed 15190372 words, keeping 145933 word types\n",
      "2019-05-04 19:56:53,361 : INFO : PROGRESS: at sentence #2800000, processed 15244693 words, keeping 145965 word types\n",
      "2019-05-04 19:56:53,382 : INFO : PROGRESS: at sentence #2810000, processed 15299522 words, keeping 145995 word types\n",
      "2019-05-04 19:56:53,403 : INFO : PROGRESS: at sentence #2820000, processed 15353941 words, keeping 146022 word types\n",
      "2019-05-04 19:56:53,425 : INFO : PROGRESS: at sentence #2830000, processed 15408737 words, keeping 146050 word types\n",
      "2019-05-04 19:56:53,446 : INFO : PROGRESS: at sentence #2840000, processed 15463497 words, keeping 146079 word types\n",
      "2019-05-04 19:56:53,467 : INFO : PROGRESS: at sentence #2850000, processed 15518121 words, keeping 146113 word types\n",
      "2019-05-04 19:56:53,488 : INFO : PROGRESS: at sentence #2860000, processed 15572812 words, keeping 146137 word types\n",
      "2019-05-04 19:56:53,508 : INFO : PROGRESS: at sentence #2870000, processed 15627568 words, keeping 146165 word types\n",
      "2019-05-04 19:56:53,529 : INFO : PROGRESS: at sentence #2880000, processed 15682346 words, keeping 146184 word types\n",
      "2019-05-04 19:56:53,549 : INFO : PROGRESS: at sentence #2890000, processed 15736476 words, keeping 146203 word types\n",
      "2019-05-04 19:56:53,570 : INFO : PROGRESS: at sentence #2900000, processed 15791579 words, keeping 146229 word types\n",
      "2019-05-04 19:56:53,593 : INFO : PROGRESS: at sentence #2910000, processed 15846766 words, keeping 146264 word types\n",
      "2019-05-04 19:56:53,614 : INFO : PROGRESS: at sentence #2920000, processed 15900907 words, keeping 146288 word types\n",
      "2019-05-04 19:56:53,634 : INFO : PROGRESS: at sentence #2930000, processed 15955846 words, keeping 146313 word types\n",
      "2019-05-04 19:56:53,655 : INFO : PROGRESS: at sentence #2940000, processed 16010885 words, keeping 146325 word types\n",
      "2019-05-04 19:56:53,676 : INFO : PROGRESS: at sentence #2950000, processed 16065872 words, keeping 146348 word types\n",
      "2019-05-04 19:56:53,696 : INFO : PROGRESS: at sentence #2960000, processed 16120814 words, keeping 146372 word types\n",
      "2019-05-04 19:56:53,718 : INFO : PROGRESS: at sentence #2970000, processed 16176390 words, keeping 146392 word types\n",
      "2019-05-04 19:56:53,741 : INFO : PROGRESS: at sentence #2980000, processed 16231613 words, keeping 146413 word types\n",
      "2019-05-04 19:56:53,762 : INFO : PROGRESS: at sentence #2990000, processed 16286259 words, keeping 146428 word types\n",
      "2019-05-04 19:56:53,784 : INFO : PROGRESS: at sentence #3000000, processed 16341762 words, keeping 146447 word types\n",
      "2019-05-04 19:56:53,805 : INFO : PROGRESS: at sentence #3010000, processed 16396493 words, keeping 146468 word types\n",
      "2019-05-04 19:56:53,826 : INFO : PROGRESS: at sentence #3020000, processed 16451867 words, keeping 146484 word types\n",
      "2019-05-04 19:56:53,847 : INFO : PROGRESS: at sentence #3030000, processed 16506106 words, keeping 146503 word types\n",
      "2019-05-04 19:56:53,867 : INFO : PROGRESS: at sentence #3040000, processed 16560728 words, keeping 146511 word types\n",
      "2019-05-04 19:56:53,888 : INFO : PROGRESS: at sentence #3050000, processed 16615725 words, keeping 146519 word types\n",
      "2019-05-04 19:56:53,910 : INFO : PROGRESS: at sentence #3060000, processed 16670220 words, keeping 146533 word types\n",
      "2019-05-04 19:56:53,931 : INFO : PROGRESS: at sentence #3070000, processed 16725568 words, keeping 146550 word types\n",
      "2019-05-04 19:56:53,952 : INFO : PROGRESS: at sentence #3080000, processed 16780228 words, keeping 146559 word types\n",
      "2019-05-04 19:56:53,973 : INFO : PROGRESS: at sentence #3090000, processed 16835161 words, keeping 146571 word types\n",
      "2019-05-04 19:56:53,994 : INFO : PROGRESS: at sentence #3100000, processed 16889992 words, keeping 146579 word types\n",
      "2019-05-04 19:56:54,015 : INFO : PROGRESS: at sentence #3110000, processed 16944655 words, keeping 146590 word types\n",
      "2019-05-04 19:56:54,037 : INFO : PROGRESS: at sentence #3120000, processed 16999622 words, keeping 146598 word types\n",
      "2019-05-04 19:56:54,060 : INFO : PROGRESS: at sentence #3130000, processed 17054141 words, keeping 146614 word types\n",
      "2019-05-04 19:56:54,080 : INFO : PROGRESS: at sentence #3140000, processed 17108344 words, keeping 146620 word types\n",
      "2019-05-04 19:56:54,101 : INFO : PROGRESS: at sentence #3150000, processed 17163053 words, keeping 146633 word types\n",
      "2019-05-04 19:56:54,121 : INFO : PROGRESS: at sentence #3160000, processed 17217788 words, keeping 146638 word types\n",
      "2019-05-04 19:56:54,141 : INFO : PROGRESS: at sentence #3170000, processed 17271783 words, keeping 146643 word types\n",
      "2019-05-04 19:56:54,162 : INFO : PROGRESS: at sentence #3180000, processed 17326896 words, keeping 146651 word types\n",
      "2019-05-04 19:56:54,182 : INFO : PROGRESS: at sentence #3190000, processed 17381544 words, keeping 146655 word types\n",
      "2019-05-04 19:56:54,203 : INFO : PROGRESS: at sentence #3200000, processed 17436137 words, keeping 146656 word types\n",
      "2019-05-04 19:56:54,222 : INFO : PROGRESS: at sentence #3210000, processed 17490552 words, keeping 146661 word types\n",
      "2019-05-04 19:56:54,242 : INFO : PROGRESS: at sentence #3220000, processed 17545769 words, keeping 146662 word types\n",
      "2019-05-04 19:56:54,262 : INFO : PROGRESS: at sentence #3230000, processed 17600137 words, keeping 146665 word types\n",
      "2019-05-04 19:56:54,289 : INFO : PROGRESS: at sentence #3240000, processed 17655377 words, keeping 146665 word types\n",
      "2019-05-04 19:56:54,309 : INFO : PROGRESS: at sentence #3250000, processed 17710119 words, keeping 146667 word types\n",
      "2019-05-04 19:56:54,330 : INFO : PROGRESS: at sentence #3260000, processed 17764921 words, keeping 146668 word types\n",
      "2019-05-04 19:56:54,351 : INFO : PROGRESS: at sentence #3270000, processed 17819153 words, keeping 146671 word types\n",
      "2019-05-04 19:56:54,372 : INFO : PROGRESS: at sentence #3280000, processed 17874341 words, keeping 146677 word types\n",
      "2019-05-04 19:56:54,393 : INFO : PROGRESS: at sentence #3290000, processed 17929356 words, keeping 146679 word types\n",
      "2019-05-04 19:56:54,414 : INFO : PROGRESS: at sentence #3300000, processed 17984034 words, keeping 146685 word types\n",
      "2019-05-04 19:56:54,436 : INFO : PROGRESS: at sentence #3310000, processed 18039001 words, keeping 146686 word types\n",
      "2019-05-04 19:56:54,456 : INFO : PROGRESS: at sentence #3320000, processed 18093783 words, keeping 146690 word types\n",
      "2019-05-04 19:56:54,477 : INFO : PROGRESS: at sentence #3330000, processed 18149094 words, keeping 146694 word types\n",
      "2019-05-04 19:56:54,497 : INFO : PROGRESS: at sentence #3340000, processed 18203718 words, keeping 146698 word types\n",
      "2019-05-04 19:56:54,518 : INFO : PROGRESS: at sentence #3350000, processed 18258827 words, keeping 146701 word types\n",
      "2019-05-04 19:56:54,538 : INFO : PROGRESS: at sentence #3360000, processed 18314063 words, keeping 146703 word types\n",
      "2019-05-04 19:56:54,557 : INFO : PROGRESS: at sentence #3370000, processed 18368660 words, keeping 146703 word types\n",
      "2019-05-04 19:56:54,579 : INFO : PROGRESS: at sentence #3380000, processed 18423326 words, keeping 146706 word types\n",
      "2019-05-04 19:56:54,599 : INFO : PROGRESS: at sentence #3390000, processed 18478079 words, keeping 146713 word types\n",
      "2019-05-04 19:56:54,620 : INFO : PROGRESS: at sentence #3400000, processed 18533116 words, keeping 146714 word types\n",
      "2019-05-04 19:56:54,640 : INFO : PROGRESS: at sentence #3410000, processed 18588273 words, keeping 146715 word types\n",
      "2019-05-04 19:56:54,661 : INFO : PROGRESS: at sentence #3420000, processed 18642623 words, keeping 146716 word types\n",
      "2019-05-04 19:56:54,683 : INFO : PROGRESS: at sentence #3430000, processed 18697521 words, keeping 146720 word types\n",
      "2019-05-04 19:56:54,709 : INFO : PROGRESS: at sentence #3440000, processed 18752400 words, keeping 146722 word types\n",
      "2019-05-04 19:56:54,733 : INFO : PROGRESS: at sentence #3450000, processed 18807487 words, keeping 146723 word types\n",
      "2019-05-04 19:56:54,755 : INFO : PROGRESS: at sentence #3460000, processed 18862285 words, keeping 146726 word types\n",
      "2019-05-04 19:56:54,778 : INFO : PROGRESS: at sentence #3470000, processed 18917732 words, keeping 146726 word types\n",
      "2019-05-04 19:56:54,801 : INFO : PROGRESS: at sentence #3480000, processed 18972133 words, keeping 146727 word types\n",
      "2019-05-04 19:56:54,822 : INFO : PROGRESS: at sentence #3490000, processed 19027093 words, keeping 146729 word types\n",
      "2019-05-04 19:56:54,843 : INFO : PROGRESS: at sentence #3500000, processed 19082555 words, keeping 146730 word types\n",
      "2019-05-04 19:56:54,864 : INFO : PROGRESS: at sentence #3510000, processed 19137679 words, keeping 146732 word types\n",
      "2019-05-04 19:56:54,885 : INFO : PROGRESS: at sentence #3520000, processed 19192920 words, keeping 146734 word types\n",
      "2019-05-04 19:56:54,908 : INFO : PROGRESS: at sentence #3530000, processed 19247551 words, keeping 146735 word types\n",
      "2019-05-04 19:56:54,929 : INFO : PROGRESS: at sentence #3540000, processed 19302281 words, keeping 146735 word types\n",
      "2019-05-04 19:56:54,952 : INFO : PROGRESS: at sentence #3550000, processed 19356682 words, keeping 146738 word types\n",
      "2019-05-04 19:56:54,973 : INFO : PROGRESS: at sentence #3560000, processed 19411457 words, keeping 146738 word types\n",
      "2019-05-04 19:56:54,994 : INFO : PROGRESS: at sentence #3570000, processed 19465533 words, keeping 146739 word types\n",
      "2019-05-04 19:56:55,014 : INFO : PROGRESS: at sentence #3580000, processed 19520354 words, keeping 146739 word types\n",
      "2019-05-04 19:56:55,035 : INFO : PROGRESS: at sentence #3590000, processed 19575051 words, keeping 146741 word types\n",
      "2019-05-04 19:56:55,057 : INFO : PROGRESS: at sentence #3600000, processed 19630008 words, keeping 146742 word types\n",
      "2019-05-04 19:56:55,077 : INFO : PROGRESS: at sentence #3610000, processed 19684863 words, keeping 146743 word types\n",
      "2019-05-04 19:56:55,098 : INFO : PROGRESS: at sentence #3620000, processed 19739676 words, keeping 146743 word types\n",
      "2019-05-04 19:56:55,119 : INFO : PROGRESS: at sentence #3630000, processed 19795002 words, keeping 146744 word types\n",
      "2019-05-04 19:56:55,141 : INFO : PROGRESS: at sentence #3640000, processed 19849577 words, keeping 146745 word types\n",
      "2019-05-04 19:56:55,162 : INFO : PROGRESS: at sentence #3650000, processed 19904502 words, keeping 146745 word types\n",
      "2019-05-04 19:56:55,182 : INFO : PROGRESS: at sentence #3660000, processed 19959623 words, keeping 146746 word types\n",
      "2019-05-04 19:56:55,204 : INFO : PROGRESS: at sentence #3670000, processed 20014321 words, keeping 146747 word types\n",
      "2019-05-04 19:56:55,226 : INFO : PROGRESS: at sentence #3680000, processed 20068876 words, keeping 146749 word types\n",
      "2019-05-04 19:56:55,247 : INFO : PROGRESS: at sentence #3690000, processed 20123446 words, keeping 146750 word types\n",
      "2019-05-04 19:56:55,269 : INFO : PROGRESS: at sentence #3700000, processed 20177944 words, keeping 146753 word types\n",
      "2019-05-04 19:56:55,293 : INFO : PROGRESS: at sentence #3710000, processed 20233222 words, keeping 146753 word types\n",
      "2019-05-04 19:56:55,317 : INFO : PROGRESS: at sentence #3720000, processed 20288202 words, keeping 146754 word types\n",
      "2019-05-04 19:56:55,339 : INFO : PROGRESS: at sentence #3730000, processed 20342995 words, keeping 146757 word types\n",
      "2019-05-04 19:56:55,362 : INFO : PROGRESS: at sentence #3740000, processed 20397876 words, keeping 146757 word types\n",
      "2019-05-04 19:56:55,385 : INFO : PROGRESS: at sentence #3750000, processed 20452657 words, keeping 146759 word types\n",
      "2019-05-04 19:56:55,408 : INFO : PROGRESS: at sentence #3760000, processed 20507528 words, keeping 146763 word types\n",
      "2019-05-04 19:56:55,431 : INFO : PROGRESS: at sentence #3770000, processed 20562583 words, keeping 146765 word types\n",
      "2019-05-04 19:56:55,452 : INFO : PROGRESS: at sentence #3780000, processed 20617195 words, keeping 146767 word types\n",
      "2019-05-04 19:56:55,473 : INFO : PROGRESS: at sentence #3790000, processed 20671878 words, keeping 146769 word types\n",
      "2019-05-04 19:56:55,495 : INFO : PROGRESS: at sentence #3800000, processed 20726814 words, keeping 146771 word types\n",
      "2019-05-04 19:56:55,515 : INFO : PROGRESS: at sentence #3810000, processed 20782013 words, keeping 146772 word types\n",
      "2019-05-04 19:56:55,537 : INFO : PROGRESS: at sentence #3820000, processed 20836506 words, keeping 146774 word types\n",
      "2019-05-04 19:56:55,558 : INFO : PROGRESS: at sentence #3830000, processed 20891522 words, keeping 146776 word types\n",
      "2019-05-04 19:56:55,578 : INFO : PROGRESS: at sentence #3840000, processed 20946566 words, keeping 146777 word types\n",
      "2019-05-04 19:56:55,600 : INFO : PROGRESS: at sentence #3850000, processed 21001747 words, keeping 146778 word types\n",
      "2019-05-04 19:56:55,622 : INFO : PROGRESS: at sentence #3860000, processed 21056463 words, keeping 146779 word types\n",
      "2019-05-04 19:56:55,643 : INFO : PROGRESS: at sentence #3870000, processed 21111458 words, keeping 146779 word types\n",
      "2019-05-04 19:56:55,666 : INFO : PROGRESS: at sentence #3880000, processed 21166037 words, keeping 146780 word types\n",
      "2019-05-04 19:56:55,691 : INFO : PROGRESS: at sentence #3890000, processed 21220562 words, keeping 146780 word types\n",
      "2019-05-04 19:56:55,714 : INFO : PROGRESS: at sentence #3900000, processed 21275610 words, keeping 146780 word types\n",
      "2019-05-04 19:56:55,735 : INFO : PROGRESS: at sentence #3910000, processed 21330370 words, keeping 146780 word types\n",
      "2019-05-04 19:56:55,755 : INFO : PROGRESS: at sentence #3920000, processed 21384994 words, keeping 146780 word types\n",
      "2019-05-04 19:56:55,777 : INFO : PROGRESS: at sentence #3930000, processed 21439447 words, keeping 146781 word types\n",
      "2019-05-04 19:56:55,798 : INFO : PROGRESS: at sentence #3940000, processed 21493831 words, keeping 146781 word types\n",
      "2019-05-04 19:56:55,820 : INFO : PROGRESS: at sentence #3950000, processed 21548766 words, keeping 146782 word types\n",
      "2019-05-04 19:56:55,842 : INFO : PROGRESS: at sentence #3960000, processed 21603676 words, keeping 146783 word types\n",
      "2019-05-04 19:56:55,864 : INFO : PROGRESS: at sentence #3970000, processed 21658305 words, keeping 146785 word types\n",
      "2019-05-04 19:56:55,887 : INFO : PROGRESS: at sentence #3980000, processed 21713150 words, keeping 146785 word types\n",
      "2019-05-04 19:56:55,910 : INFO : PROGRESS: at sentence #3990000, processed 21768668 words, keeping 146787 word types\n",
      "2019-05-04 19:56:55,931 : INFO : PROGRESS: at sentence #4000000, processed 21823774 words, keeping 146787 word types\n",
      "2019-05-04 19:56:55,952 : INFO : PROGRESS: at sentence #4010000, processed 21878653 words, keeping 146787 word types\n",
      "2019-05-04 19:56:55,973 : INFO : PROGRESS: at sentence #4020000, processed 21932815 words, keeping 146788 word types\n",
      "2019-05-04 19:56:55,995 : INFO : PROGRESS: at sentence #4030000, processed 21988169 words, keeping 146788 word types\n",
      "2019-05-04 19:56:56,017 : INFO : PROGRESS: at sentence #4040000, processed 22042850 words, keeping 146790 word types\n",
      "2019-05-04 19:56:56,039 : INFO : PROGRESS: at sentence #4050000, processed 22097836 words, keeping 146791 word types\n",
      "2019-05-04 19:56:56,061 : INFO : PROGRESS: at sentence #4060000, processed 22152671 words, keeping 146792 word types\n",
      "2019-05-04 19:56:56,082 : INFO : PROGRESS: at sentence #4070000, processed 22208306 words, keeping 146792 word types\n",
      "2019-05-04 19:56:56,103 : INFO : PROGRESS: at sentence #4080000, processed 22263158 words, keeping 146792 word types\n",
      "2019-05-04 19:56:56,125 : INFO : PROGRESS: at sentence #4090000, processed 22317990 words, keeping 146792 word types\n",
      "2019-05-04 19:56:56,147 : INFO : PROGRESS: at sentence #4100000, processed 22372951 words, keeping 146792 word types\n",
      "2019-05-04 19:56:56,171 : INFO : PROGRESS: at sentence #4110000, processed 22427739 words, keeping 146793 word types\n",
      "2019-05-04 19:56:56,193 : INFO : PROGRESS: at sentence #4120000, processed 22483024 words, keeping 146794 word types\n",
      "2019-05-04 19:56:56,213 : INFO : PROGRESS: at sentence #4130000, processed 22537197 words, keeping 146794 word types\n",
      "2019-05-04 19:56:56,233 : INFO : PROGRESS: at sentence #4140000, processed 22591384 words, keeping 146794 word types\n",
      "2019-05-04 19:56:56,254 : INFO : PROGRESS: at sentence #4150000, processed 22646041 words, keeping 146795 word types\n",
      "2019-05-04 19:56:56,275 : INFO : PROGRESS: at sentence #4160000, processed 22700995 words, keeping 146796 word types\n",
      "2019-05-04 19:56:56,296 : INFO : PROGRESS: at sentence #4170000, processed 22755905 words, keeping 146797 word types\n",
      "2019-05-04 19:56:56,317 : INFO : PROGRESS: at sentence #4180000, processed 22811214 words, keeping 146798 word types\n",
      "2019-05-04 19:56:56,338 : INFO : PROGRESS: at sentence #4190000, processed 22865922 words, keeping 146799 word types\n",
      "2019-05-04 19:56:56,359 : INFO : PROGRESS: at sentence #4200000, processed 22920588 words, keeping 146799 word types\n",
      "2019-05-04 19:56:56,380 : INFO : PROGRESS: at sentence #4210000, processed 22975050 words, keeping 146802 word types\n",
      "2019-05-04 19:56:56,401 : INFO : PROGRESS: at sentence #4220000, processed 23030105 words, keeping 146804 word types\n",
      "2019-05-04 19:56:56,424 : INFO : PROGRESS: at sentence #4230000, processed 23084878 words, keeping 146804 word types\n",
      "2019-05-04 19:56:56,447 : INFO : PROGRESS: at sentence #4240000, processed 23139453 words, keeping 146806 word types\n",
      "2019-05-04 19:56:56,471 : INFO : PROGRESS: at sentence #4250000, processed 23194486 words, keeping 146807 word types\n",
      "2019-05-04 19:56:56,495 : INFO : PROGRESS: at sentence #4260000, processed 23249044 words, keeping 146809 word types\n",
      "2019-05-04 19:56:56,519 : INFO : PROGRESS: at sentence #4270000, processed 23304044 words, keeping 146810 word types\n",
      "2019-05-04 19:56:56,541 : INFO : PROGRESS: at sentence #4280000, processed 23358873 words, keeping 146811 word types\n",
      "2019-05-04 19:56:56,564 : INFO : PROGRESS: at sentence #4290000, processed 23413443 words, keeping 146811 word types\n",
      "2019-05-04 19:56:56,586 : INFO : PROGRESS: at sentence #4300000, processed 23468317 words, keeping 146811 word types\n",
      "2019-05-04 19:56:56,610 : INFO : PROGRESS: at sentence #4310000, processed 23523159 words, keeping 146812 word types\n",
      "2019-05-04 19:56:56,632 : INFO : PROGRESS: at sentence #4320000, processed 23577874 words, keeping 146813 word types\n",
      "2019-05-04 19:56:56,655 : INFO : PROGRESS: at sentence #4330000, processed 23632683 words, keeping 146813 word types\n",
      "2019-05-04 19:56:56,677 : INFO : PROGRESS: at sentence #4340000, processed 23687800 words, keeping 146814 word types\n",
      "2019-05-04 19:56:56,699 : INFO : PROGRESS: at sentence #4350000, processed 23742463 words, keeping 146814 word types\n",
      "2019-05-04 19:56:56,720 : INFO : PROGRESS: at sentence #4360000, processed 23797098 words, keeping 146814 word types\n",
      "2019-05-04 19:56:56,742 : INFO : PROGRESS: at sentence #4370000, processed 23852258 words, keeping 146815 word types\n",
      "2019-05-04 19:56:56,764 : INFO : PROGRESS: at sentence #4380000, processed 23906907 words, keeping 146816 word types\n",
      "2019-05-04 19:56:56,788 : INFO : PROGRESS: at sentence #4390000, processed 23961687 words, keeping 146816 word types\n",
      "2019-05-04 19:56:56,810 : INFO : PROGRESS: at sentence #4400000, processed 24016023 words, keeping 146817 word types\n",
      "2019-05-04 19:56:56,834 : INFO : PROGRESS: at sentence #4410000, processed 24070873 words, keeping 146818 word types\n",
      "2019-05-04 19:56:56,857 : INFO : PROGRESS: at sentence #4420000, processed 24125792 words, keeping 146818 word types\n",
      "2019-05-04 19:56:56,879 : INFO : PROGRESS: at sentence #4430000, processed 24180717 words, keeping 146818 word types\n",
      "2019-05-04 19:56:56,902 : INFO : PROGRESS: at sentence #4440000, processed 24235310 words, keeping 146819 word types\n",
      "2019-05-04 19:56:56,925 : INFO : PROGRESS: at sentence #4450000, processed 24289922 words, keeping 146819 word types\n",
      "2019-05-04 19:56:56,946 : INFO : PROGRESS: at sentence #4460000, processed 24344614 words, keeping 146819 word types\n",
      "2019-05-04 19:56:56,967 : INFO : PROGRESS: at sentence #4470000, processed 24399288 words, keeping 146819 word types\n",
      "2019-05-04 19:56:56,988 : INFO : PROGRESS: at sentence #4480000, processed 24453811 words, keeping 146819 word types\n",
      "2019-05-04 19:56:57,009 : INFO : PROGRESS: at sentence #4490000, processed 24508875 words, keeping 146819 word types\n",
      "2019-05-04 19:56:57,030 : INFO : PROGRESS: at sentence #4500000, processed 24563765 words, keeping 146819 word types\n",
      "2019-05-04 19:56:57,051 : INFO : PROGRESS: at sentence #4510000, processed 24618467 words, keeping 146821 word types\n",
      "2019-05-04 19:56:57,075 : INFO : PROGRESS: at sentence #4520000, processed 24672433 words, keeping 146822 word types\n",
      "2019-05-04 19:56:57,097 : INFO : PROGRESS: at sentence #4530000, processed 24727161 words, keeping 146822 word types\n",
      "2019-05-04 19:56:57,119 : INFO : PROGRESS: at sentence #4540000, processed 24782053 words, keeping 146823 word types\n",
      "2019-05-04 19:56:57,139 : INFO : PROGRESS: at sentence #4550000, processed 24837382 words, keeping 146823 word types\n",
      "2019-05-04 19:56:57,161 : INFO : PROGRESS: at sentence #4560000, processed 24892483 words, keeping 146823 word types\n",
      "2019-05-04 19:56:57,182 : INFO : PROGRESS: at sentence #4570000, processed 24947500 words, keeping 146824 word types\n",
      "2019-05-04 19:56:57,204 : INFO : PROGRESS: at sentence #4580000, processed 25001909 words, keeping 146824 word types\n",
      "2019-05-04 19:56:57,225 : INFO : PROGRESS: at sentence #4590000, processed 25056602 words, keeping 146824 word types\n",
      "2019-05-04 19:56:57,247 : INFO : PROGRESS: at sentence #4600000, processed 25111975 words, keeping 146824 word types\n",
      "2019-05-04 19:56:57,268 : INFO : PROGRESS: at sentence #4610000, processed 25166912 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,289 : INFO : PROGRESS: at sentence #4620000, processed 25221239 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,311 : INFO : PROGRESS: at sentence #4630000, processed 25275989 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,333 : INFO : PROGRESS: at sentence #4640000, processed 25330854 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,355 : INFO : PROGRESS: at sentence #4650000, processed 25385790 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,376 : INFO : PROGRESS: at sentence #4660000, processed 25440539 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,397 : INFO : PROGRESS: at sentence #4670000, processed 25494899 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,418 : INFO : PROGRESS: at sentence #4680000, processed 25549906 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,438 : INFO : PROGRESS: at sentence #4690000, processed 25604850 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,462 : INFO : PROGRESS: at sentence #4700000, processed 25659245 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,483 : INFO : PROGRESS: at sentence #4710000, processed 25714063 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,503 : INFO : PROGRESS: at sentence #4720000, processed 25768355 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,524 : INFO : PROGRESS: at sentence #4730000, processed 25823896 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,544 : INFO : PROGRESS: at sentence #4740000, processed 25879292 words, keeping 146827 word types\n",
      "2019-05-04 19:56:57,564 : INFO : PROGRESS: at sentence #4750000, processed 25934166 words, keeping 146828 word types\n",
      "2019-05-04 19:56:57,585 : INFO : PROGRESS: at sentence #4760000, processed 25988808 words, keeping 146830 word types\n",
      "2019-05-04 19:56:57,605 : INFO : PROGRESS: at sentence #4770000, processed 26043785 words, keeping 146831 word types\n",
      "2019-05-04 19:56:57,627 : INFO : PROGRESS: at sentence #4780000, processed 26098281 words, keeping 146831 word types\n",
      "2019-05-04 19:56:57,648 : INFO : PROGRESS: at sentence #4790000, processed 26153302 words, keeping 146831 word types\n",
      "2019-05-04 19:56:57,669 : INFO : PROGRESS: at sentence #4800000, processed 26208414 words, keeping 146832 word types\n",
      "2019-05-04 19:56:57,690 : INFO : PROGRESS: at sentence #4810000, processed 26263319 words, keeping 146832 word types\n",
      "2019-05-04 19:56:57,711 : INFO : PROGRESS: at sentence #4820000, processed 26318238 words, keeping 146832 word types\n",
      "2019-05-04 19:56:57,731 : INFO : PROGRESS: at sentence #4830000, processed 26372930 words, keeping 146832 word types\n",
      "2019-05-04 19:56:57,752 : INFO : PROGRESS: at sentence #4840000, processed 26427479 words, keeping 146833 word types\n",
      "2019-05-04 19:56:57,773 : INFO : PROGRESS: at sentence #4850000, processed 26481952 words, keeping 146833 word types\n",
      "2019-05-04 19:56:57,795 : INFO : PROGRESS: at sentence #4860000, processed 26536616 words, keeping 146833 word types\n",
      "2019-05-04 19:56:57,817 : INFO : PROGRESS: at sentence #4870000, processed 26591249 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,838 : INFO : PROGRESS: at sentence #4880000, processed 26645710 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,860 : INFO : PROGRESS: at sentence #4890000, processed 26700979 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,883 : INFO : PROGRESS: at sentence #4900000, processed 26755960 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,906 : INFO : PROGRESS: at sentence #4910000, processed 26810704 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,928 : INFO : PROGRESS: at sentence #4920000, processed 26865400 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,950 : INFO : PROGRESS: at sentence #4930000, processed 26920581 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,972 : INFO : PROGRESS: at sentence #4940000, processed 26975368 words, keeping 146834 word types\n",
      "2019-05-04 19:56:57,993 : INFO : PROGRESS: at sentence #4950000, processed 27030098 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,013 : INFO : PROGRESS: at sentence #4960000, processed 27084706 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,034 : INFO : PROGRESS: at sentence #4970000, processed 27139475 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,055 : INFO : PROGRESS: at sentence #4980000, processed 27195394 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,079 : INFO : PROGRESS: at sentence #4990000, processed 27250472 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,100 : INFO : PROGRESS: at sentence #5000000, processed 27305357 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,123 : INFO : PROGRESS: at sentence #5010000, processed 27360216 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,146 : INFO : PROGRESS: at sentence #5020000, processed 27414742 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,170 : INFO : PROGRESS: at sentence #5030000, processed 27469367 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,194 : INFO : PROGRESS: at sentence #5040000, processed 27524377 words, keeping 146834 word types\n",
      "2019-05-04 19:56:58,218 : INFO : PROGRESS: at sentence #5050000, processed 27579140 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,242 : INFO : PROGRESS: at sentence #5060000, processed 27634277 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,267 : INFO : PROGRESS: at sentence #5070000, processed 27689114 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,291 : INFO : PROGRESS: at sentence #5080000, processed 27744242 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,316 : INFO : PROGRESS: at sentence #5090000, processed 27799268 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,341 : INFO : PROGRESS: at sentence #5100000, processed 27854138 words, keeping 146835 word types\n",
      "2019-05-04 19:56:58,364 : INFO : PROGRESS: at sentence #5110000, processed 27908945 words, keeping 146836 word types\n",
      "2019-05-04 19:56:58,388 : INFO : PROGRESS: at sentence #5120000, processed 27963422 words, keeping 146836 word types\n",
      "2019-05-04 19:56:58,412 : INFO : PROGRESS: at sentence #5130000, processed 28018098 words, keeping 146836 word types\n",
      "2019-05-04 19:56:58,435 : INFO : PROGRESS: at sentence #5140000, processed 28072510 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,457 : INFO : PROGRESS: at sentence #5150000, processed 28127288 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,480 : INFO : PROGRESS: at sentence #5160000, processed 28181306 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,502 : INFO : PROGRESS: at sentence #5170000, processed 28236767 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,523 : INFO : PROGRESS: at sentence #5180000, processed 28292258 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,544 : INFO : PROGRESS: at sentence #5190000, processed 28346893 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,565 : INFO : PROGRESS: at sentence #5200000, processed 28401736 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,586 : INFO : PROGRESS: at sentence #5210000, processed 28456865 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,607 : INFO : PROGRESS: at sentence #5220000, processed 28511496 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,629 : INFO : PROGRESS: at sentence #5230000, processed 28566134 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,651 : INFO : PROGRESS: at sentence #5240000, processed 28620524 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,674 : INFO : PROGRESS: at sentence #5250000, processed 28675645 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,697 : INFO : PROGRESS: at sentence #5260000, processed 28730178 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,719 : INFO : PROGRESS: at sentence #5270000, processed 28785227 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,742 : INFO : PROGRESS: at sentence #5280000, processed 28840246 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,765 : INFO : PROGRESS: at sentence #5290000, processed 28894916 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,788 : INFO : PROGRESS: at sentence #5300000, processed 28950109 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,812 : INFO : PROGRESS: at sentence #5310000, processed 29004515 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,834 : INFO : PROGRESS: at sentence #5320000, processed 29059607 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,856 : INFO : PROGRESS: at sentence #5330000, processed 29114221 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,877 : INFO : PROGRESS: at sentence #5340000, processed 29169592 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,900 : INFO : PROGRESS: at sentence #5350000, processed 29224761 words, keeping 146837 word types\n",
      "2019-05-04 19:56:58,923 : INFO : PROGRESS: at sentence #5360000, processed 29279750 words, keeping 146838 word types\n",
      "2019-05-04 19:56:58,944 : INFO : PROGRESS: at sentence #5370000, processed 29334853 words, keeping 146838 word types\n",
      "2019-05-04 19:56:58,965 : INFO : PROGRESS: at sentence #5380000, processed 29389084 words, keeping 146838 word types\n",
      "2019-05-04 19:56:58,986 : INFO : PROGRESS: at sentence #5390000, processed 29444162 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,007 : INFO : PROGRESS: at sentence #5400000, processed 29498214 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,028 : INFO : PROGRESS: at sentence #5410000, processed 29552780 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,049 : INFO : PROGRESS: at sentence #5420000, processed 29608013 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,069 : INFO : PROGRESS: at sentence #5430000, processed 29662754 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,091 : INFO : PROGRESS: at sentence #5440000, processed 29717486 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,111 : INFO : PROGRESS: at sentence #5450000, processed 29772114 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,132 : INFO : PROGRESS: at sentence #5460000, processed 29826586 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,153 : INFO : PROGRESS: at sentence #5470000, processed 29881612 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,174 : INFO : PROGRESS: at sentence #5480000, processed 29936294 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,194 : INFO : PROGRESS: at sentence #5490000, processed 29990891 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,215 : INFO : PROGRESS: at sentence #5500000, processed 30044871 words, keeping 146838 word types\n",
      "2019-05-04 19:56:59,215 : INFO : collected 146838 word types from a corpus of 30045808 raw words and 5500172 sentences\n",
      "2019-05-04 19:56:59,216 : INFO : Loading a fresh vocabulary\n",
      "2019-05-04 19:57:00,039 : INFO : effective_min_count=7 retains 76505 unique words (52% of original 146838, drops 70333)\n",
      "2019-05-04 19:57:00,040 : INFO : effective_min_count=7 leaves 29827436 word corpus (99% of original 30045808, drops 218372)\n",
      "2019-05-04 19:57:00,298 : INFO : deleting the raw counts dictionary of 146838 items\n",
      "2019-05-04 19:57:00,306 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2019-05-04 19:57:00,307 : INFO : downsampling leaves estimated 28737875 word corpus (96.3% of prior 29827436)\n",
      "2019-05-04 19:57:00,628 : INFO : estimated required memory for 76505 words and 128 dimensions: 116593620 bytes\n",
      "2019-05-04 19:57:00,629 : INFO : resetting layer weights\n",
      "2019-05-04 19:57:01,484 : INFO : training model with 3 workers on 76505 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-04 19:57:02,502 : INFO : EPOCH 1 - PROGRESS: at 1.68% examples, 460728 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:03,528 : INFO : EPOCH 1 - PROGRESS: at 3.49% examples, 475640 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:04,548 : INFO : EPOCH 1 - PROGRESS: at 5.43% examples, 493851 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:05,591 : INFO : EPOCH 1 - PROGRESS: at 7.24% examples, 490757 words/s, in_qsize 6, out_qsize 2\n",
      "2019-05-04 19:57:06,607 : INFO : EPOCH 1 - PROGRESS: at 8.86% examples, 482226 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:07,609 : INFO : EPOCH 1 - PROGRESS: at 10.41% examples, 474598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:08,615 : INFO : EPOCH 1 - PROGRESS: at 12.00% examples, 470204 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:09,616 : INFO : EPOCH 1 - PROGRESS: at 13.59% examples, 467123 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:10,636 : INFO : EPOCH 1 - PROGRESS: at 15.16% examples, 463911 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:11,677 : INFO : EPOCH 1 - PROGRESS: at 16.72% examples, 460689 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:12,690 : INFO : EPOCH 1 - PROGRESS: at 18.24% examples, 458377 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:13,693 : INFO : EPOCH 1 - PROGRESS: at 19.77% examples, 456800 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:14,702 : INFO : EPOCH 1 - PROGRESS: at 21.29% examples, 455271 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:15,721 : INFO : EPOCH 1 - PROGRESS: at 22.85% examples, 454332 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:16,727 : INFO : EPOCH 1 - PROGRESS: at 24.61% examples, 457652 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:17,730 : INFO : EPOCH 1 - PROGRESS: at 26.37% examples, 460625 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:18,750 : INFO : EPOCH 1 - PROGRESS: at 28.15% examples, 463383 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:19,761 : INFO : EPOCH 1 - PROGRESS: at 29.94% examples, 466044 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:20,769 : INFO : EPOCH 1 - PROGRESS: at 31.74% examples, 468497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:21,774 : INFO : EPOCH 1 - PROGRESS: at 33.46% examples, 469834 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:22,810 : INFO : EPOCH 1 - PROGRESS: at 35.29% examples, 471713 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:23,831 : INFO : EPOCH 1 - PROGRESS: at 37.11% examples, 473732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:24,846 : INFO : EPOCH 1 - PROGRESS: at 38.91% examples, 475302 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:25,878 : INFO : EPOCH 1 - PROGRESS: at 40.73% examples, 476772 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:26,914 : INFO : EPOCH 1 - PROGRESS: at 42.58% examples, 478460 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:27,939 : INFO : EPOCH 1 - PROGRESS: at 44.35% examples, 479112 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:28,940 : INFO : EPOCH 1 - PROGRESS: at 46.17% examples, 480822 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:29,944 : INFO : EPOCH 1 - PROGRESS: at 47.95% examples, 482027 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:57:30,947 : INFO : EPOCH 1 - PROGRESS: at 49.71% examples, 482855 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:31,947 : INFO : EPOCH 1 - PROGRESS: at 51.54% examples, 484291 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:32,953 : INFO : EPOCH 1 - PROGRESS: at 53.27% examples, 484651 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-04 19:57:33,963 : INFO : EPOCH 1 - PROGRESS: at 55.09% examples, 485789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:34,997 : INFO : EPOCH 1 - PROGRESS: at 56.91% examples, 486521 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:36,005 : INFO : EPOCH 1 - PROGRESS: at 58.71% examples, 487292 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:37,025 : INFO : EPOCH 1 - PROGRESS: at 60.50% examples, 487840 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:38,044 : INFO : EPOCH 1 - PROGRESS: at 62.35% examples, 488914 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:39,055 : INFO : EPOCH 1 - PROGRESS: at 64.20% examples, 490021 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:40,057 : INFO : EPOCH 1 - PROGRESS: at 66.00% examples, 490687 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:41,063 : INFO : EPOCH 1 - PROGRESS: at 67.82% examples, 491526 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:42,068 : INFO : EPOCH 1 - PROGRESS: at 69.58% examples, 491838 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:43,087 : INFO : EPOCH 1 - PROGRESS: at 71.40% examples, 492458 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:44,089 : INFO : EPOCH 1 - PROGRESS: at 73.16% examples, 492779 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:45,103 : INFO : EPOCH 1 - PROGRESS: at 74.94% examples, 493163 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:46,127 : INFO : EPOCH 1 - PROGRESS: at 76.60% examples, 492577 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:47,155 : INFO : EPOCH 1 - PROGRESS: at 78.10% examples, 490956 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-04 19:57:48,175 : INFO : EPOCH 1 - PROGRESS: at 79.62% examples, 489615 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:49,176 : INFO : EPOCH 1 - PROGRESS: at 81.15% examples, 488574 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:50,196 : INFO : EPOCH 1 - PROGRESS: at 82.61% examples, 486991 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:51,220 : INFO : EPOCH 1 - PROGRESS: at 84.13% examples, 485822 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:52,221 : INFO : EPOCH 1 - PROGRESS: at 85.66% examples, 484912 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:53,225 : INFO : EPOCH 1 - PROGRESS: at 87.12% examples, 483635 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:54,261 : INFO : EPOCH 1 - PROGRESS: at 88.65% examples, 482488 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:55,274 : INFO : EPOCH 1 - PROGRESS: at 90.14% examples, 481408 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:56,274 : INFO : EPOCH 1 - PROGRESS: at 91.76% examples, 481179 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:57,287 : INFO : EPOCH 1 - PROGRESS: at 93.55% examples, 481715 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:57:58,317 : INFO : EPOCH 1 - PROGRESS: at 95.27% examples, 481738 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:57:59,330 : INFO : EPOCH 1 - PROGRESS: at 97.13% examples, 482565 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:00,349 : INFO : EPOCH 1 - PROGRESS: at 98.95% examples, 483221 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:00,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-04 19:58:00,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-04 19:58:00,884 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-04 19:58:00,885 : INFO : EPOCH - 1 : training on 30045808 raw words (28737523 effective words) took 59.4s, 483863 effective words/s\n",
      "2019-05-04 19:58:01,896 : INFO : EPOCH 2 - PROGRESS: at 1.88% examples, 520064 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:02,902 : INFO : EPOCH 2 - PROGRESS: at 3.80% examples, 524003 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:03,912 : INFO : EPOCH 2 - PROGRESS: at 5.74% examples, 527837 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:04,929 : INFO : EPOCH 2 - PROGRESS: at 7.68% examples, 528871 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:05,931 : INFO : EPOCH 2 - PROGRESS: at 9.57% examples, 529058 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:06,964 : INFO : EPOCH 2 - PROGRESS: at 11.52% examples, 529729 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-04 19:58:07,977 : INFO : EPOCH 2 - PROGRESS: at 13.45% examples, 530361 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:08,984 : INFO : EPOCH 2 - PROGRESS: at 15.33% examples, 530214 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:10,016 : INFO : EPOCH 2 - PROGRESS: at 17.18% examples, 529010 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:11,040 : INFO : EPOCH 2 - PROGRESS: at 19.07% examples, 529453 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:12,058 : INFO : EPOCH 2 - PROGRESS: at 20.89% examples, 528334 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:13,079 : INFO : EPOCH 2 - PROGRESS: at 22.79% examples, 528901 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:58:14,109 : INFO : EPOCH 2 - PROGRESS: at 24.58% examples, 526828 words/s, in_qsize 6, out_qsize 2\n",
      "2019-05-04 19:58:15,128 : INFO : EPOCH 2 - PROGRESS: at 26.47% examples, 527438 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:16,189 : INFO : EPOCH 2 - PROGRESS: at 28.25% examples, 524683 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:17,193 : INFO : EPOCH 2 - PROGRESS: at 29.91% examples, 521724 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-04 19:58:18,199 : INFO : EPOCH 2 - PROGRESS: at 31.77% examples, 522371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:19,208 : INFO : EPOCH 2 - PROGRESS: at 33.59% examples, 522358 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:20,211 : INFO : EPOCH 2 - PROGRESS: at 35.29% examples, 520528 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:21,213 : INFO : EPOCH 2 - PROGRESS: at 37.08% examples, 520317 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:22,232 : INFO : EPOCH 2 - PROGRESS: at 38.94% examples, 520600 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:23,258 : INFO : EPOCH 2 - PROGRESS: at 40.80% examples, 520682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:24,265 : INFO : EPOCH 2 - PROGRESS: at 42.62% examples, 520791 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:25,290 : INFO : EPOCH 2 - PROGRESS: at 44.41% examples, 520101 words/s, in_qsize 6, out_qsize 2\n",
      "2019-05-04 19:58:26,305 : INFO : EPOCH 2 - PROGRESS: at 46.07% examples, 518167 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:27,318 : INFO : EPOCH 2 - PROGRESS: at 47.62% examples, 515326 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:28,343 : INFO : EPOCH 2 - PROGRESS: at 49.15% examples, 512148 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:29,362 : INFO : EPOCH 2 - PROGRESS: at 50.68% examples, 509289 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:30,389 : INFO : EPOCH 2 - PROGRESS: at 52.21% examples, 506490 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:31,409 : INFO : EPOCH 2 - PROGRESS: at 53.80% examples, 504637 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:32,418 : INFO : EPOCH 2 - PROGRESS: at 55.29% examples, 502162 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:33,438 : INFO : EPOCH 2 - PROGRESS: at 56.84% examples, 500254 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:34,446 : INFO : EPOCH 2 - PROGRESS: at 58.38% examples, 498356 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:35,476 : INFO : EPOCH 2 - PROGRESS: at 59.93% examples, 496524 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:36,498 : INFO : EPOCH 2 - PROGRESS: at 61.69% examples, 496520 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:37,505 : INFO : EPOCH 2 - PROGRESS: at 63.54% examples, 497506 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:58:38,532 : INFO : EPOCH 2 - PROGRESS: at 65.43% examples, 498414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:39,556 : INFO : EPOCH 2 - PROGRESS: at 67.32% examples, 499331 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:40,557 : INFO : EPOCH 2 - PROGRESS: at 69.18% examples, 500239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:41,562 : INFO : EPOCH 2 - PROGRESS: at 70.93% examples, 500352 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:58:42,571 : INFO : EPOCH 2 - PROGRESS: at 72.72% examples, 500641 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:43,584 : INFO : EPOCH 2 - PROGRESS: at 74.58% examples, 501312 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:44,593 : INFO : EPOCH 2 - PROGRESS: at 76.40% examples, 501783 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:45,607 : INFO : EPOCH 2 - PROGRESS: at 78.26% examples, 502404 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:46,616 : INFO : EPOCH 2 - PROGRESS: at 80.09% examples, 502835 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:47,632 : INFO : EPOCH 2 - PROGRESS: at 81.98% examples, 503569 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:48,671 : INFO : EPOCH 2 - PROGRESS: at 83.87% examples, 504040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:49,675 : INFO : EPOCH 2 - PROGRESS: at 85.69% examples, 504461 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:50,680 : INFO : EPOCH 2 - PROGRESS: at 87.48% examples, 504654 words/s, in_qsize 6, out_qsize 2\n",
      "2019-05-04 19:58:51,685 : INFO : EPOCH 2 - PROGRESS: at 89.34% examples, 505230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:52,695 : INFO : EPOCH 2 - PROGRESS: at 91.16% examples, 505540 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:53,710 : INFO : EPOCH 2 - PROGRESS: at 92.98% examples, 505789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:54,724 : INFO : EPOCH 2 - PROGRESS: at 94.77% examples, 505866 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:58:55,760 : INFO : EPOCH 2 - PROGRESS: at 96.63% examples, 506081 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:56,785 : INFO : EPOCH 2 - PROGRESS: at 98.49% examples, 506390 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:58:57,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-04 19:58:57,580 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-04 19:58:57,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-04 19:58:57,582 : INFO : EPOCH - 2 : training on 30045808 raw words (28738253 effective words) took 56.7s, 506943 effective words/s\n",
      "2019-05-04 19:58:58,610 : INFO : EPOCH 3 - PROGRESS: at 1.81% examples, 493003 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:58:59,620 : INFO : EPOCH 3 - PROGRESS: at 3.76% examples, 514062 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:00,621 : INFO : EPOCH 3 - PROGRESS: at 5.71% examples, 522698 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:01,638 : INFO : EPOCH 3 - PROGRESS: at 7.61% examples, 522557 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:02,638 : INFO : EPOCH 3 - PROGRESS: at 9.54% examples, 526090 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:03,653 : INFO : EPOCH 3 - PROGRESS: at 11.46% examples, 527245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:04,685 : INFO : EPOCH 3 - PROGRESS: at 13.42% examples, 528177 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:05,692 : INFO : EPOCH 3 - PROGRESS: at 15.29% examples, 528319 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:06,724 : INFO : EPOCH 3 - PROGRESS: at 17.18% examples, 528377 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:07,727 : INFO : EPOCH 3 - PROGRESS: at 19.03% examples, 529014 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:08,743 : INFO : EPOCH 3 - PROGRESS: at 20.89% examples, 528920 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:09,759 : INFO : EPOCH 3 - PROGRESS: at 22.75% examples, 528867 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:10,767 : INFO : EPOCH 3 - PROGRESS: at 24.58% examples, 528378 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:11,789 : INFO : EPOCH 3 - PROGRESS: at 26.43% examples, 528106 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:12,793 : INFO : EPOCH 3 - PROGRESS: at 28.29% examples, 528495 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:13,822 : INFO : EPOCH 3 - PROGRESS: at 30.11% examples, 527457 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:59:14,834 : INFO : EPOCH 3 - PROGRESS: at 31.97% examples, 527592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:15,863 : INFO : EPOCH 3 - PROGRESS: at 33.83% examples, 527223 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:16,865 : INFO : EPOCH 3 - PROGRESS: at 35.62% examples, 526676 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:17,866 : INFO : EPOCH 3 - PROGRESS: at 37.45% examples, 526636 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:18,877 : INFO : EPOCH 3 - PROGRESS: at 39.27% examples, 526368 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:19,878 : INFO : EPOCH 3 - PROGRESS: at 41.09% examples, 526358 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:20,905 : INFO : EPOCH 3 - PROGRESS: at 42.89% examples, 525361 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-04 19:59:21,926 : INFO : EPOCH 3 - PROGRESS: at 44.81% examples, 526138 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:22,927 : INFO : EPOCH 3 - PROGRESS: at 46.60% examples, 525747 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:23,936 : INFO : EPOCH 3 - PROGRESS: at 48.42% examples, 525620 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:24,945 : INFO : EPOCH 3 - PROGRESS: at 50.27% examples, 525833 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:25,962 : INFO : EPOCH 3 - PROGRESS: at 52.11% examples, 525543 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:26,987 : INFO : EPOCH 3 - PROGRESS: at 53.99% examples, 525799 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:27,991 : INFO : EPOCH 3 - PROGRESS: at 55.88% examples, 526392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:29,020 : INFO : EPOCH 3 - PROGRESS: at 57.71% examples, 525924 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:30,026 : INFO : EPOCH 3 - PROGRESS: at 59.54% examples, 525832 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:59:31,037 : INFO : EPOCH 3 - PROGRESS: at 61.39% examples, 525961 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:32,050 : INFO : EPOCH 3 - PROGRESS: at 63.24% examples, 526056 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:33,078 : INFO : EPOCH 3 - PROGRESS: at 65.17% examples, 526455 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:34,096 : INFO : EPOCH 3 - PROGRESS: at 67.02% examples, 526453 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:35,099 : INFO : EPOCH 3 - PROGRESS: at 68.88% examples, 526675 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:36,100 : INFO : EPOCH 3 - PROGRESS: at 70.70% examples, 526652 words/s, in_qsize 3, out_qsize 2\n",
      "2019-05-04 19:59:37,101 : INFO : EPOCH 3 - PROGRESS: at 72.59% examples, 527113 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:38,123 : INFO : EPOCH 3 - PROGRESS: at 74.48% examples, 527280 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:39,129 : INFO : EPOCH 3 - PROGRESS: at 76.30% examples, 527181 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 19:59:40,139 : INFO : EPOCH 3 - PROGRESS: at 78.19% examples, 527491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:41,151 : INFO : EPOCH 3 - PROGRESS: at 80.05% examples, 527538 words/s, in_qsize 4, out_qsize 0\n",
      "2019-05-04 19:59:42,167 : INFO : EPOCH 3 - PROGRESS: at 81.94% examples, 527755 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 19:59:43,168 : INFO : EPOCH 3 - PROGRESS: at 83.73% examples, 527499 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:44,179 : INFO : EPOCH 3 - PROGRESS: at 85.56% examples, 527361 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:45,208 : INFO : EPOCH 3 - PROGRESS: at 87.42% examples, 527222 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:46,215 : INFO : EPOCH 3 - PROGRESS: at 89.21% examples, 526932 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-04 19:59:47,222 : INFO : EPOCH 3 - PROGRESS: at 90.76% examples, 525306 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:48,257 : INFO : EPOCH 3 - PROGRESS: at 92.32% examples, 523454 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:49,258 : INFO : EPOCH 3 - PROGRESS: at 93.85% examples, 521830 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:50,276 : INFO : EPOCH 3 - PROGRESS: at 95.34% examples, 519929 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:51,296 : INFO : EPOCH 3 - PROGRESS: at 96.90% examples, 518425 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:52,329 : INFO : EPOCH 3 - PROGRESS: at 98.49% examples, 517034 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:53,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-04 19:59:53,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-04 19:59:53,275 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-04 19:59:53,275 : INFO : EPOCH - 3 : training on 30045808 raw words (28736820 effective words) took 55.7s, 516058 effective words/s\n",
      "2019-05-04 19:59:54,314 : INFO : EPOCH 4 - PROGRESS: at 1.61% examples, 432671 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:55,342 : INFO : EPOCH 4 - PROGRESS: at 3.25% examples, 437765 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:56,344 : INFO : EPOCH 4 - PROGRESS: at 4.89% examples, 443160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:57,348 : INFO : EPOCH 4 - PROGRESS: at 6.80% examples, 464450 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:58,357 : INFO : EPOCH 4 - PROGRESS: at 8.69% examples, 476762 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 19:59:59,372 : INFO : EPOCH 4 - PROGRESS: at 10.61% examples, 486177 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:00,388 : INFO : EPOCH 4 - PROGRESS: at 12.50% examples, 491391 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:01,402 : INFO : EPOCH 4 - PROGRESS: at 14.46% examples, 497755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:00:02,428 : INFO : EPOCH 4 - PROGRESS: at 16.35% examples, 501576 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:03,443 : INFO : EPOCH 4 - PROGRESS: at 18.24% examples, 505164 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:04,450 : INFO : EPOCH 4 - PROGRESS: at 20.16% examples, 509389 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:05,461 : INFO : EPOCH 4 - PROGRESS: at 22.02% examples, 511172 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:06,465 : INFO : EPOCH 4 - PROGRESS: at 23.88% examples, 512920 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:07,476 : INFO : EPOCH 4 - PROGRESS: at 25.77% examples, 514852 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:08,503 : INFO : EPOCH 4 - PROGRESS: at 27.69% examples, 516613 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:09,517 : INFO : EPOCH 4 - PROGRESS: at 29.58% examples, 517977 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:10,518 : INFO : EPOCH 4 - PROGRESS: at 31.41% examples, 518438 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:11,519 : INFO : EPOCH 4 - PROGRESS: at 33.26% examples, 519402 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:12,522 : INFO : EPOCH 4 - PROGRESS: at 35.12% examples, 520198 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:13,537 : INFO : EPOCH 4 - PROGRESS: at 37.02% examples, 521071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:14,540 : INFO : EPOCH 4 - PROGRESS: at 38.87% examples, 521713 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:15,549 : INFO : EPOCH 4 - PROGRESS: at 40.73% examples, 522146 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:16,579 : INFO : EPOCH 4 - PROGRESS: at 42.62% examples, 522491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:17,597 : INFO : EPOCH 4 - PROGRESS: at 44.51% examples, 523068 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:18,608 : INFO : EPOCH 4 - PROGRESS: at 46.43% examples, 524116 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:19,616 : INFO : EPOCH 4 - PROGRESS: at 48.25% examples, 524069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:20,629 : INFO : EPOCH 4 - PROGRESS: at 50.08% examples, 523909 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:21,640 : INFO : EPOCH 4 - PROGRESS: at 51.94% examples, 524145 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:22,648 : INFO : EPOCH 4 - PROGRESS: at 53.83% examples, 524738 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:23,672 : INFO : EPOCH 4 - PROGRESS: at 55.68% examples, 524722 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:24,696 : INFO : EPOCH 4 - PROGRESS: at 57.51% examples, 524380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:25,700 : INFO : EPOCH 4 - PROGRESS: at 59.37% examples, 524668 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:26,713 : INFO : EPOCH 4 - PROGRESS: at 61.22% examples, 524807 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-04 20:00:27,719 : INFO : EPOCH 4 - PROGRESS: at 63.11% examples, 525320 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:00:28,720 : INFO : EPOCH 4 - PROGRESS: at 64.97% examples, 525612 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:29,752 : INFO : EPOCH 4 - PROGRESS: at 66.86% examples, 525698 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-04 20:00:30,772 : INFO : EPOCH 4 - PROGRESS: at 68.65% examples, 525184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:31,777 : INFO : EPOCH 4 - PROGRESS: at 70.54% examples, 525651 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:32,791 : INFO : EPOCH 4 - PROGRESS: at 72.40% examples, 525727 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:33,806 : INFO : EPOCH 4 - PROGRESS: at 74.28% examples, 526015 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:34,826 : INFO : EPOCH 4 - PROGRESS: at 76.14% examples, 525991 words/s, in_qsize 6, out_qsize 2\n",
      "2019-05-04 20:00:35,833 : INFO : EPOCH 4 - PROGRESS: at 78.00% examples, 526150 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:36,853 : INFO : EPOCH 4 - PROGRESS: at 79.89% examples, 526354 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:37,884 : INFO : EPOCH 4 - PROGRESS: at 81.78% examples, 526423 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:38,916 : INFO : EPOCH 4 - PROGRESS: at 83.67% examples, 526471 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-04 20:00:39,929 : INFO : EPOCH 4 - PROGRESS: at 85.56% examples, 526737 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:40,939 : INFO : EPOCH 4 - PROGRESS: at 87.42% examples, 526817 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:41,965 : INFO : EPOCH 4 - PROGRESS: at 89.31% examples, 526920 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:42,965 : INFO : EPOCH 4 - PROGRESS: at 91.09% examples, 526721 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:43,974 : INFO : EPOCH 4 - PROGRESS: at 92.92% examples, 526620 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:44,975 : INFO : EPOCH 4 - PROGRESS: at 94.77% examples, 526795 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:45,983 : INFO : EPOCH 4 - PROGRESS: at 96.63% examples, 526885 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:46,999 : INFO : EPOCH 4 - PROGRESS: at 98.49% examples, 526901 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:47,770 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-04 20:00:47,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-04 20:00:47,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-04 20:00:47,787 : INFO : EPOCH - 4 : training on 30045808 raw words (28737829 effective words) took 54.5s, 527268 effective words/s\n",
      "2019-05-04 20:00:48,805 : INFO : EPOCH 5 - PROGRESS: at 1.92% examples, 530991 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:49,832 : INFO : EPOCH 5 - PROGRESS: at 3.90% examples, 533427 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:50,845 : INFO : EPOCH 5 - PROGRESS: at 5.84% examples, 533404 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:51,846 : INFO : EPOCH 5 - PROGRESS: at 7.78% examples, 535133 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:52,848 : INFO : EPOCH 5 - PROGRESS: at 9.71% examples, 535985 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:00:53,857 : INFO : EPOCH 5 - PROGRESS: at 11.66% examples, 537576 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:54,886 : INFO : EPOCH 5 - PROGRESS: at 13.65% examples, 538517 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:55,911 : INFO : EPOCH 5 - PROGRESS: at 15.56% examples, 537466 words/s, in_qsize 3, out_qsize 2\n",
      "2019-05-04 20:00:56,934 : INFO : EPOCH 5 - PROGRESS: at 17.45% examples, 536996 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:00:57,943 : INFO : EPOCH 5 - PROGRESS: at 19.30% examples, 536453 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:58,967 : INFO : EPOCH 5 - PROGRESS: at 21.15% examples, 535332 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:00:59,970 : INFO : EPOCH 5 - PROGRESS: at 22.99% examples, 534483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:00,999 : INFO : EPOCH 5 - PROGRESS: at 24.77% examples, 532006 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:02,018 : INFO : EPOCH 5 - PROGRESS: at 26.66% examples, 532285 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:03,018 : INFO : EPOCH 5 - PROGRESS: at 28.52% examples, 532539 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:04,027 : INFO : EPOCH 5 - PROGRESS: at 30.38% examples, 532479 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:05,047 : INFO : EPOCH 5 - PROGRESS: at 32.30% examples, 533182 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:06,051 : INFO : EPOCH 5 - PROGRESS: at 34.16% examples, 533240 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:07,057 : INFO : EPOCH 5 - PROGRESS: at 35.85% examples, 530759 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:08,074 : INFO : EPOCH 5 - PROGRESS: at 37.38% examples, 525850 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:09,086 : INFO : EPOCH 5 - PROGRESS: at 38.94% examples, 521996 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:10,102 : INFO : EPOCH 5 - PROGRESS: at 40.50% examples, 518392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:11,120 : INFO : EPOCH 5 - PROGRESS: at 42.06% examples, 515073 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:12,126 : INFO : EPOCH 5 - PROGRESS: at 43.58% examples, 511889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:13,143 : INFO : EPOCH 5 - PROGRESS: at 45.14% examples, 509094 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:14,163 : INFO : EPOCH 5 - PROGRESS: at 46.66% examples, 506106 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:15,173 : INFO : EPOCH 5 - PROGRESS: at 48.25% examples, 504231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:16,191 : INFO : EPOCH 5 - PROGRESS: at 49.75% examples, 501336 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:17,193 : INFO : EPOCH 5 - PROGRESS: at 51.44% examples, 500866 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:18,210 : INFO : EPOCH 5 - PROGRESS: at 53.37% examples, 502372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:19,240 : INFO : EPOCH 5 - PROGRESS: at 55.25% examples, 503285 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-04 20:01:20,249 : INFO : EPOCH 5 - PROGRESS: at 57.11% examples, 504150 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:21,250 : INFO : EPOCH 5 - PROGRESS: at 58.94% examples, 504803 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:22,252 : INFO : EPOCH 5 - PROGRESS: at 60.79% examples, 505679 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:23,262 : INFO : EPOCH 5 - PROGRESS: at 62.72% examples, 506925 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:24,284 : INFO : EPOCH 5 - PROGRESS: at 64.57% examples, 507422 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:25,309 : INFO : EPOCH 5 - PROGRESS: at 66.49% examples, 508350 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:26,315 : INFO : EPOCH 5 - PROGRESS: at 68.38% examples, 509253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:27,325 : INFO : EPOCH 5 - PROGRESS: at 70.27% examples, 510026 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:28,350 : INFO : EPOCH 5 - PROGRESS: at 72.16% examples, 510595 words/s, in_qsize 3, out_qsize 2\n",
      "2019-05-04 20:01:29,353 : INFO : EPOCH 5 - PROGRESS: at 74.08% examples, 511624 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:30,374 : INFO : EPOCH 5 - PROGRESS: at 75.97% examples, 512170 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:31,380 : INFO : EPOCH 5 - PROGRESS: at 77.76% examples, 512205 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:32,384 : INFO : EPOCH 5 - PROGRESS: at 79.62% examples, 512695 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:33,398 : INFO : EPOCH 5 - PROGRESS: at 81.51% examples, 513268 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:34,410 : INFO : EPOCH 5 - PROGRESS: at 83.41% examples, 513832 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:35,427 : INFO : EPOCH 5 - PROGRESS: at 85.30% examples, 514311 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:36,436 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 514669 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:37,445 : INFO : EPOCH 5 - PROGRESS: at 89.01% examples, 515005 words/s, in_qsize 3, out_qsize 2\n",
      "2019-05-04 20:01:38,449 : INFO : EPOCH 5 - PROGRESS: at 90.90% examples, 515580 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:39,482 : INFO : EPOCH 5 - PROGRESS: at 92.82% examples, 516014 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-04 20:01:40,500 : INFO : EPOCH 5 - PROGRESS: at 94.74% examples, 516581 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-04 20:01:41,533 : INFO : EPOCH 5 - PROGRESS: at 96.63% examples, 516799 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:42,556 : INFO : EPOCH 5 - PROGRESS: at 98.49% examples, 516936 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-04 20:01:43,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-04 20:01:43,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-04 20:01:43,333 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-04 20:01:43,334 : INFO : EPOCH - 5 : training on 30045808 raw words (28738105 effective words) took 55.5s, 517529 effective words/s\n",
      "2019-05-04 20:01:43,335 : INFO : training on a 150229040 raw words (143688530 effective words) took 281.8s, 509807 effective words/s\n"
     ]
    }
   ],
   "source": [
    "emb_mod = gensim.models.Word2Vec(all_texts, min_count=7, size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "e3f42f65-d5fe-9fcb-968e-25c9bc6681e4"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-95826a53f5d7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-95826a53f5d7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for i in range(n_epochs)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# You might want to train the model more to get better results\n",
    "n_epochs = 5\n",
    "for i in range(n_epochs)\n",
    "    emb_mod.train(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a37196c-9892-37a9-d1a5-3d3c5330c794"
   },
   "source": [
    "### Build a vocabulary of token identifiers and prepare word embedding matrix\n",
    "Here we only add tokens present in the embedding model to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5b1e02c3-c41c-f9d6-9ca5-fc3c069c6a3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:81: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "voc, rev_voc = build_vocab(all_texts, \n",
    "                           75000, emb_mod)\n",
    "embs_m = get_embeddings(emb_mod, rev_voc, emb_mod.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed236db3-a829-2133-b8b0-214801b0d24a"
   },
   "source": [
    "### Represent train/test texts with token identifiers\n",
    "max_len of 24 tokens seems to be sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "9c649246-5f9b-2605-5f79-f2c28935a1e4"
   },
   "outputs": [],
   "source": [
    "v_tr_q1 = vectorize(tr_q1_preprocessed, voc, max_len=24)\n",
    "v_tr_q2 = vectorize(tr_q2_preprocessed, voc, max_len=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "63cbcb60-dec5-de9c-6d37-c963453ffe02"
   },
   "outputs": [],
   "source": [
    "v_ts_q1 = vectorize(ts_q1_preprocessed, voc, max_len=24)\n",
    "v_ts_q2 = vectorize(ts_q2_preprocessed, voc, max_len=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "d578e2f1-9045-a238-19cc-2f3ee8f7eacf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed19546f-0255-ecdd-ab7e-38f233906c00"
   },
   "source": [
    "### (Optional) Dump assets to disk\n",
    "We might continue from there in case the kernel is reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "857d476e-9acc-a25d-5e22-a0280b44cd28"
   },
   "outputs": [],
   "source": [
    "pickle.dump([v_tr_q1, v_tr_q2], open(\"vectorized_train\", \"wb\"))\n",
    "pickle.dump([v_ts_q1, v_ts_q2], open(\"vectorized_test\", \"wb\"))\n",
    "pickle.dump([voc, rev_voc], open(\"voc_rvoc\", \"wb\"))\n",
    "pickle.dump(embs_m, open(\"embedding_matrix\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "80d2e188-8058-9965-9dee-295284bb6fdc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './assets/vectorized_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0ec7d14ae17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv_tr_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_tr_q2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./assets/vectorized_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv_ts_q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_ts_q2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./assets/vectorized_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_voc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./assets/voc_rvoc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membs_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./assets/embedding_matrix\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './assets/vectorized_train'"
     ]
    }
   ],
   "source": [
    "v_tr_q1, v_tr_q2 = pickle.load(open(\"./assets/vectorized_train\", \"rb\"))\n",
    "v_ts_q1, v_ts_q2 = pickle.load(open(\"./assets/vectorized_test\", \"rb\"))\n",
    "voc, rev_voc = pickle.load(open(\"./assets/voc_rvoc\", \"rb\"))\n",
    "embs_m = pickle.load(open(\"./assets/embedding_matrix\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "2ad667c2-8649-0675-6c78-4d1c8196860c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca841d75-8f06-be2b-533c-140deefc0fee"
   },
   "source": [
    "### Define a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "4dae93a4-b577-28d0-41f9-07fafcd7b1b4"
   },
   "outputs": [],
   "source": [
    "MAXLEN = 24\n",
    "DROPOUT = 0.5\n",
    "LSTM_UNITS = 600\n",
    "DENSE_UNITS = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "29331df3-9bf9-4370-b072-37127c0bfb95"
   },
   "outputs": [],
   "source": [
    "def pairwise_dis(vests):\n",
    "    x, y = vests\n",
    "    return x-y\n",
    "\n",
    "def pairwise_mul(vests):\n",
    "    x, y = vests\n",
    "    return x*y\n",
    "\n",
    "def cosine_similarity(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return K.sum((x * y), axis=-1, keepdims=True)\n",
    "\n",
    "def cosine_distance_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1[0], 1\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "d9f9f3a0-6283-b1b0-0c51-c9c42cf0fb80"
   },
   "outputs": [],
   "source": [
    "def build_rnn_mk1_encoder(embs_matrix):\n",
    "    \"\"\"\n",
    "    Basic Bidirectional LSTM encoder. \n",
    "    Word embedding layer is frozen to prevent overfitting.\n",
    "    \"\"\"\n",
    "    inp = Input(shape=(MAXLEN,))\n",
    "    emb = Embedding(embs_matrix.shape[0], embs_matrix.shape[1], input_length=MAXLEN, \n",
    "                    weights=[embs_matrix], trainable = False)(inp)\n",
    "    ls1 = Bidirectional(LSTM(LSTM_UNITS))(emb)\n",
    "    mod = Model(inputs=inp, outputs=ls1)\n",
    "    return mod\n",
    "\n",
    "def build_sim_net(input_shape):\n",
    "    \"\"\"\n",
    "    MLP combining the representations of two question into one vector.\n",
    "    Takes into account distanse and angle between the input vectors.\n",
    "    For more information check out the blog post\n",
    "    https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning\n",
    "    \"\"\"\n",
    "    input_a = Input(shape=(input_shape[1],))\n",
    "    input_b = Input(shape=(input_shape[1],))\n",
    "    \n",
    "    mul_layer = Lambda(pairwise_mul, name='MultiplicationLayer')([input_a, input_b])\n",
    "    dis_layer = Lambda(pairwise_dis, name='SubstractionLayer')([input_a, input_b])\n",
    "\n",
    "    mer = concatenate([mul_layer, dis_layer])\n",
    "    bnr = BatchNormalization()(mer)\n",
    "    \n",
    "    dr1 = Dropout(DROPOUT)(bnr)\n",
    "    fc1 = Dense(DENSE_UNITS, activation='relu')(dr1)\n",
    "    \n",
    "    mod = Model(inputs=[input_a, input_b], outputs=fc1)\n",
    "    return mod\n",
    "\n",
    "def build_model(embs_matrix):\n",
    "    \"\"\"\n",
    "    Combines the modules above into an end-to-end model\n",
    "    predicting similarity scores for pairs of questions.\n",
    "    \n",
    "    Keep in mind that you can plug in just about anything in place of the encoder.\n",
    "    As long as it predicts a fixed-length vector for each sentence, it should just work.\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = build_rnn_mk1_encoder(embs_matrix)\n",
    "    simnet = build_sim_net(encoder.layers[-1].output_shape)\n",
    "    \n",
    "    input_a = Input(shape=(MAXLEN,))\n",
    "    input_b = Input(shape=(MAXLEN,))\n",
    "    \n",
    "    enc_a = encoder(input_a)\n",
    "    enc_b = encoder(input_b)\n",
    "    \n",
    "    fc1 = simnet([enc_a, enc_b])\n",
    "    \n",
    "    fc2 = Dense(1, activation='sigmoid')(fc1)\n",
    "    \n",
    "    model = Model(inputs=[input_a, input_b], outputs=fc2)\n",
    "    feature_model = Model(inputs=[input_a, input_b], outputs=fc1)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model, feature_model, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9345068c-1555-b61a-8173-da70ab85e571"
   },
   "source": [
    "### Build the neural network\n",
    "The first one predicts similarity score, the second returns a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "6df9bbfb-6ab9-47c5-561a-1a7fda6a20bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 20:02:51,416 : WARNING : From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 20:02:55,613 : WARNING : From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "mmod, fmod, encmod = build_model(embs_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "59bf085d-d4da-8f12-1396-33a9e65ff0a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 24, 128)           9600000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1200)              3499200   \n",
      "=================================================================\n",
      "Total params: 13,099,200\n",
      "Trainable params: 3,499,200\n",
      "Non-trainable params: 9,600,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bfdbefc0-eca0-22bf-5e5e-1fdaa2e4a0f5"
   },
   "source": [
    "### Do the train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "1d5aaa55-e9aa-c1f8-fedb-9cb49464064e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(len(v_tr_q1)))\n",
    "random.shuffle(idx)\n",
    "train_idx, val_idx = train_test_split(idx, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "0f4b34b0-5ee5-60df-9695-a0b6d909b4d4"
   },
   "outputs": [],
   "source": [
    "train_X = [v_tr_q1[train_idx], v_tr_q2[train_idx]]\n",
    "train_Y = labels[train_idx]\n",
    "\n",
    "val_X = [v_tr_q1[val_idx], v_tr_q2[val_idx]]\n",
    "val_Y = labels[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07976505-1361-8085-32ea-7165f639418a"
   },
   "source": [
    "## Train!\n",
    "Training this takes ~1 hour on a GTX 1080 with recent CUDA/CUDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "49af117d-f74d-8c21-7001-a9adab02d4b7"
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"quora_bilstm.hdf5\",\n",
    "                                       verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "32c88270-349a-3c1c-021a-e5b7f13c5119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-04 20:02:57,632 : WARNING : From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363861 samples, validate on 40429 samples\n",
      "Epoch 1/20\n",
      "363861/363861 [==============================] - 200s 550us/step - loss: 0.4627 - acc: 0.7647 - val_loss: 0.4307 - val_acc: 0.7835\n",
      "Epoch 2/20\n",
      "363861/363861 [==============================] - 198s 544us/step - loss: 0.4128 - acc: 0.7960 - val_loss: 0.4045 - val_acc: 0.8026\n",
      "Epoch 3/20\n",
      "363861/363861 [==============================] - 196s 538us/step - loss: 0.3998 - acc: 0.8091 - val_loss: 0.3970 - val_acc: 0.8049\n",
      "Epoch 4/20\n",
      "327168/363861 [=========================>....] - ETA: 19s - loss: 0.3614 - acc: 0.8275"
     ]
    }
   ],
   "source": [
    "hist = mmod.fit(train_X, train_Y, validation_data=(val_X, val_Y), \n",
    "                batch_size=256, epochs=20, \n",
    "                callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "88f706ba-8d4a-517c-ac9d-038420d282ad"
   },
   "outputs": [],
   "source": [
    "mmod.load_weights(\"quora_bilstm.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "070581e7-c9d6-de12-77fc-5368866c0c2a"
   },
   "source": [
    "### Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "d5908d50-a4c3-1e06-a33c-aa1b4e578f93"
   },
   "outputs": [],
   "source": [
    "predictions = mmod.predict([v_ts_q1, v_ts_q2]).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "5ff6974e-2661-c8cc-8e68-7f08e9f4cfb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.251524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.406096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.289482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.626289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.004301\n",
       "1        1      0.251524\n",
       "2        2      0.406096\n",
       "3        3      0.289482\n",
       "4        4      0.626289"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'test_id': testing_data['test_id'], 'is_duplicate': predictions})\n",
    "sub.to_csv('sample_submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "09bfd61a-e5fa-bafa-b5c2-766536f2de2c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "5a28ac3c-3669-7518-6b52-fbd396379bbb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
